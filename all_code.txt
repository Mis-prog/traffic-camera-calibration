# ==== source/__init__.py ====
"""
calibration_toolkit
~~~~~~~~~~~~~~~~~~~~
–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∫–∞–º–µ—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ—á–µ–∫ —Å—Ö–æ–¥–∞, —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π —Å—Ü–µ–Ω—ã
–∏ –¥–æ–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—á–Ω—É—é, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∏ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É.
"""
from .calibration import CalibrationPipeline
from .calibration import RefineOptimizer
from .core import Camera, PointND
from .calibration import VanishingPointCalibration
__all__ = [
    "CalibrationPipeline",
    "RefineOptimizer",
    "Camera",
    "VanishingPointCalibration",
    "PointND",
]
__version__ = "0.2.0"
__author__ = "–ê–∫–º—É—Ä–∑–∏–Ω –ú–∏—Ö–∞–∏–ª"
__email__ = "akmurzinmihail@gmail.com"
__description__ = "–ú–æ–¥—É–ª—å –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∫–∞–º–µ—Ä—ã –∏ –¥–æ–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —Ç–æ—á–∫–∞–º —Å—Ö–æ–¥–∞ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Å—Ü–µ–Ω—ã."# ==== source/core/__init__.py ====
from .camera import Camera
from .pointND import PointND
from .camera_intrinsics import CameraIntrinsics
from .camera_extrinsics import CameraExtrinsics
__all__ = [
    "Camera",
    "PointND",
    "CameraIntrinsics",
    "CameraExtrinsics"
]
__version__ = "0.1.0"
__author__ = "–ê–∫–º—É—Ä–∑–∏–Ω –ú–∏—à–∞"# ==== source/core/camera.py ====
import cv2
import numpy as np
from .camera_intrinsics import CameraIntrinsics
from .camera_extrinsics import CameraExtrinsics
from .pointND import PointND
class Camera:
    def __init__(self, path_image):
        self.image = cv2.cvtColor(cv2.imread(path_image), cv2.COLOR_BGR2RGB)
        self.size = self.image.shape[:2]
        self.path = path_image
        self.intrinsics = CameraIntrinsics(self.size[1], self.size[0])
        self.extrinsics = CameraExtrinsics()
    def set_params(self, params: dict):
        """
        –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–º–µ—Ä—ã –∏–∑ —Å–ª–æ–≤–∞—Ä—è.
        –û–∂–∏–¥–∞–µ–º—ã–µ –∫–ª—é—á–∏:
            - f –∏–ª–∏ (fx, fy): —Ñ–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–æ–¥–Ω–æ –∏–ª–∏ –¥–≤–∞)
            - rz, rx, ry: —É–≥–ª—ã –≠–π–ª–µ—Ä–∞ –≤ –≥—Ä–∞–¥—É—Å–∞—Ö (–µ—Å–ª–∏ from_type='euler')
            - vp: —Å–ø–∏—Å–æ–∫ –∏–∑ —Ç—Ä—ë—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π (–µ—Å–ª–∏ from_type='vp')
            - x, y, z: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ø–æ–ª–æ–∂–µ–Ω–∏—è –∫–∞–º–µ—Ä—ã
            - from_type: 'euler' –∏–ª–∏ 'vp'
        """
        # --- —Ñ–æ–∫—É—Å ---
        if "f" in params:
            self.intrinsics.set_focal_length(params["f"])
        elif "fx" in params and "fy" in params:
            self.intrinsics.set_focal_length((params["fx"], params["fy"]))
        else:
            raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ñ–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (f –∏–ª–∏ fx/fy)")
        # --- –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è ---
        from_type = params.get("from_type", "euler")
        if from_type == "euler":
            angles = [params.get("rz", 0), params.get("rx", 0), params.get("ry", 0)]
            self.extrinsics.set_rotation(angles, from_type="euler")
        elif from_type == "vp":
            vp_list = params.get("vp")
            if vp_list is None or len(vp_list) != 3:
                raise ValueError("–î–ª—è from_type='vp' –Ω—É–∂–Ω–æ —Ç—Ä–∏ –≤–µ–∫—Ç–æ—Ä–∞ vp")
            self.extrinsics.set_rotation(vp_list, from_type="vp")
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø from_type: {from_type}")
        # --- –ø–æ–∑–∏—Ü–∏—è ---
        x = params.get("x", 0)
        y = params.get("y", 0)
        z = params.get("z", 0)
        self.extrinsics.set_position(x, y, z)
    def set_params_from_list(self, param_list: list):
        """
        –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–º–µ—Ä—ã –∏–∑ –ø–ª–æ—Å–∫–æ–≥–æ —Å–ø–∏—Å–∫–∞.
        –û–∂–∏–¥–∞–µ—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç: [f, rz, rx, ry, x, y, z]
        """
        if len(param_list) != 7:
            raise ValueError("–û–∂–∏–¥–∞–µ—Ç—Å—è 7 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: f, rz, rx, ry, x, y, z")
        f = param_list[0]
        rz, rx, ry = param_list[1:4]
        x, y, z = param_list[4:7]
        self.intrinsics.set_focal_length(f)
        self.extrinsics.set_rotation([rz, rx, ry], from_type="euler")
        self.extrinsics.set_position(x, y, z)
    def get_params(self) -> list:
        params = []
        f = self.intrinsics.get_focal_length()
        if isinstance(f, tuple):  # fx, fy
            params.extend(f)
        else:
            params.append(f)
        rz, rx, ry = self.extrinsics.get_angles()
        params.extend([rz, rx, ry])
        x, y, z = self.extrinsics.get_position()
        assert isinstance(x, float)
        params.extend([x, y, z])
        return params
    def get_image(self):
        return self.image
    def get_size(self):
        return self.size
    def project_direct(self, point3D: PointND) -> PointND:
        RT = self.extrinsics.get()
        K = self.intrinsics.get()
        P = K @ RT
        point2D = PointND(P @ point3D.get(out_homogeneous=True), add_weight=False)
        return point2D
    def project_back(self, point2D: PointND, plane_z: float = 0.0) -> PointND:
        K = self.intrinsics.get()
        R = self.extrinsics.get_rotation()
        C = np.array(self.extrinsics.get_position())
        x = point2D.get(out_homogeneous=True)
        # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª—É—á–∞ –≤ —Å–∏—Å—Ç–µ–º–µ –º–∏—Ä–∞
        K_inv = np.linalg.inv(K)
        ray_cam = K_inv @ x  # –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤ —Å–∏—Å—Ç–µ–º–µ –∫–∞–º–µ—Ä—ã
        ray_world = R.T @ ray_cam  # –≤ –º–∏—Ä–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –Ω–æ –º–æ–∂–Ω–æ)
        ray_world = ray_world / np.linalg.norm(ray_world)
        # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å –ø–ª–æ—Å–∫–æ—Å—Ç—å—é Z = plane_z
        t = (plane_z - C[2]) / ray_world[2]  # –∏—â–µ–º —Ç–∞–∫–æ–π t, —á—Ç–æ–±—ã Z == plane_z
        point3D = C + t * ray_world  # —Ç–æ—á–∫–∞ –Ω–∞ –ø–ª–æ—Å–∫–æ—Å—Ç–∏
        return PointND(point3D, add_weight=True)
def homography(self, point: PointND, direction='direct') -> PointND:
    RT = self.extrinsics.get()
    RT = np.delete(RT, 2, axis=1)  # —É–¥–∞–ª—è–µ–º —Ç—Ä–µ—Ç–∏–π —Å—Ç–æ–ª–±–µ—Ü (–æ—Å–∏ Z) ‚áí –ø—Ä–æ–µ–∫—Ü–∏—è –Ω–∞ –ø–ª–æ—Å–∫–æ—Å—Ç—å Z=0
    H = self.intrinsics.get() @ RT  # –ì–æ–º–æ–≥—Ä–∞—Ñ–∏—è
    p = point.get(out_homogeneous=True)
    if direction == 'direct':
        transformed = H @ p
    elif direction == 'back':
        H_inv = np.linalg.inv(H)
        transformed = H_inv @ p
    else:
        raise ValueError("–ê—Ä–≥—É–º–µ–Ω—Ç direction –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'direct' –∏–ª–∏ 'back'.")
    return PointND(transformed, add_weight=False)
# ==== source/core/camera_extrinsics.py ====
import numpy as np
from scipy.spatial.transform import Rotation
class CameraExtrinsics:
    def __init__(self):
        self.R = np.eye(3)
        self.C = np.array([0, 0, 10])
    def set_rotation(self, data, from_type='euler'):
        if from_type == 'euler':
            self.R = Rotation.from_euler('zxy', data, degrees=True).as_matrix()
        elif from_type == 'vp':
            if data.shape == (3, 3):
                self.R = data
            else:
                raise ValueError("–û–∂–∏–¥–∞–µ—Ç—Å—è –º–∞—Ç—Ä–∏—Ü–∞ 3x3 –¥–ª—è from_type='vp'")
        else:
            raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏")
    def set_position(self, x=0, y=0, z=10):
        self.C = np.array([x, y, z])
    def get_rotation(self):
        return self.R
    def get_angles(self, order='zxy', degrees=True):
        """
        :return: (rz, rx, ry)
        """
        return Rotation.from_matrix(self.R).as_euler(order, degrees=degrees)
    def get_position(self):
        return tuple(float(c) for c in np.ravel(self.C))
    def get(self):
        t = -self.R @ self.C
        RT = np.hstack([self.R, t.reshape(3, 1)])
        return RT
# ==== source/core/camera_intrinsics.py ====
import numpy as np
class CameraIntrinsics:
    def __init__(self, width, height):
        self.width = width
        self.height = height
        self.fx = None
        self.fy = None
        self.K = np.eye(3)
    def set_focal_length(self, f):
        self.fx, self.fy = (f, f) if not isinstance(f, (tuple, list)) else f
        self.K = np.array([[self.fx, 0, self.width / 2],
                           [0, self.fy, self.height / 2],
                           [0, 0, 1]])
    def get(self):
        return self.K
    def get_main_point(self):
        return self.width / 2, self.height / 2
    def get_focal_length(self):
        if self.fx == self.fy:
            return self.fx
        else:
            return (self.fx, self.fy)
# ==== source/core/pointND.py ====
import numpy as np
class PointND:
    def __init__(self, coord, add_weight=True):
        coord = np.asarray(coord)
        if len(coord) + 1 in [3, 4] and add_weight:
            coord = np.append(coord, 1)
        self.coord = coord
    def set(self, coord):
        self.coord = np.append(coord, 1) if len(coord) + 1 == len(self.coord) else coord
    def get(self, out_homogeneous=False):
        return self.coord if out_homogeneous else self.coord[:-1] / self.coord[-1]
    def get_type(self):
        dim = len(self.coord) - 1
        return f"{dim}D"
    def set_Z(self, z):
        if len(self.coord) > 3:
            self.coord[2] = z
        else:
            raise ValueError("–û–±—ä–µ–∫—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è 3D —Ç–æ—á–∫–æ–π")
# ==== source/utils/__init__.py ====
from .data_markup_tool import AnnotationTool
from .annotation_parser import AnnotationParser
__all__ = [
    "AnnotationTool",
    "AnnotationParser",
]
# ==== source/utils/annotation_parser.py ====
import json
from collections import defaultdict
class AnnotationParser:
    def __init__(self, filepath):
        self.filepath = filepath
        self.annotations = {"line": {}, "point": {}}
        self._load()
    def _load(self):
        with open(self.filepath, "r", encoding="utf-8") as f:
            self.annotations = json.load(f)
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –æ–±–∞ —Ç–∏–ø–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
            self.annotations.setdefault("line", {})
            self.annotations.setdefault("point", {})
    def get_all_classes(self):
        classes = set(self.annotations["lines"].keys()) | set(self.annotations["points"].keys())
        return sorted(classes)
    def get_points_by_class(self, class_name):
        return self.annotations["point"].get(class_name, [])
    def get_lines_by_class(self, class_name):
        return self.annotations["line"].get(class_name, [])
    def get_all_points(self):
        all_points = []
        for cls, pts in self.annotations["point"].items():
            all_points.extend(pts)
        return all_points
    def get_all_lines(self):
        all_lines = []
        for cls, lines in self.annotations["line"].items():
            all_lines.extend(lines)
        return all_lines
    def count_per_class(self):
        stats = {}
        for cls in self.get_all_classes():
            stats[cls] = {
                "point": len(self.get_points_by_class(cls)),
                "line": len(self.get_lines_by_class(cls))
            }
        return stats
if __name__ == "__main__":
    parser = AnnotationParser("../../example/karls_marks/marked/data_full.json")
    print("–ö–ª–∞—Å—Å—ã:", parser.get_all_classes())
    print("–¢–æ—á–µ–∫ –≤—Å–µ–≥–æ:", len(parser.get_all_points()))
    print("–õ–∏–Ω–∏–π –≤—Å–µ–≥–æ:", len(parser.get_all_lines()))
    stats = parser.count_per_class()
    for cls, s in stats.items():
        print(f"{cls}: {s['points']} —Ç–æ—á–µ–∫, {s['lines']} –ª–∏–Ω–∏–π")# ==== source/utils/data_markup_tool.py ====
import sys
import json
import hashlib
import colorsys
from PyQt5.QtWidgets import (
    QApplication, QMainWindow, QLabel, QPushButton, QFileDialog,
    QVBoxLayout, QHBoxLayout, QComboBox, QWidget
)
from PyQt5.QtGui import QPixmap, QPainter, QPen, QColor, QFont
from PyQt5.QtCore import Qt, QPoint
class AnnotationTool(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Annotation Tool")
        # –í–∏–¥–∂–µ—Ç—ã
        self.image_label = QLabel()
        self.image_label.setMouseTracking(True)
        self.image_label.mousePressEvent = self.mouse_press_event
        self.image_label.mouseMoveEvent = self.mouse_move_event
        self.image_label.mouseReleaseEvent = self.mouse_release_event
        self.load_btn = QPushButton("–ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        self.load_btn.clicked.connect(self.load_image)
        self.save_btn = QPushButton("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏")
        self.save_btn.clicked.connect(self.save_annotations)
        self.load_ann_btn = QPushButton("–ó–∞–≥—Ä—É–∑–∏—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏")
        self.load_ann_btn.clicked.connect(self.load_annotations)
        self.mode_selector = QComboBox()
        self.mode_selector.addItem("–¢–æ—á–∫–∞", "point")
        self.mode_selector.addItem("–õ–∏–Ω–∏—è", "line")
        self.class_selector = QComboBox()
        self.class_selector.setEditable(True)
        self.class_selector.addItem("default")
        self.add_class_btn = QPushButton("–î–æ–±–∞–≤–∏—Ç—å –∫–ª–∞—Å—Å")
        self.add_class_btn.clicked.connect(self.add_class)
        # Layout
        top_bar = QHBoxLayout()
        for widget in [self.load_btn, self.load_ann_btn, self.save_btn,
                       self.mode_selector, self.class_selector, self.add_class_btn]:
            top_bar.addWidget(widget)
        layout = QVBoxLayout()
        layout.addLayout(top_bar)
        layout.addWidget(self.image_label)
        container = QWidget()
        container.setLayout(layout)
        self.setCentralWidget(container)
        # –õ–æ–≥–∏–∫–∞
        self.image = None
        self.scaled_image = None
        self.display_scale = 1.0
        self.annotations = {"point": {}, "line": {}}
        self.current_line = []
        self.selected = None
        self.dragging = False
        self.hover = None
    def load_image(self):
        path, _ = QFileDialog.getOpenFileName(self, "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        if not path:
            return
        self.image = QPixmap(path)
        self.update_scale()
        self.update_display()
    def update_scale(self):
        max_width = 1280
        if self.image.width() > max_width:
            self.display_scale = max_width / self.image.width()
            self.scaled_image = self.image.scaledToWidth(max_width, Qt.SmoothTransformation)
        else:
            self.display_scale = 1.0
            self.scaled_image = self.image
    def get_mouse_pos(self, event):
        x = event.pos().x() / self.display_scale
        y = event.pos().y() / self.display_scale
        return int(x), int(y)
    def mouse_press_event(self, event):
        if not self.image:
            return
        x, y = self.get_mouse_pos(event)
        cls = self.class_selector.currentText().strip()
        mode = self.mode_selector.currentData()
        if cls and self.class_selector.findText(cls) == -1:
            self.class_selector.addItem(cls)
        if event.button() == Qt.RightButton:
            self.try_delete_nearest(x, y)
            return
        self.selected = self.find_nearest_point(x, y)
        if self.selected:
            self.dragging = True
            return
        if mode == "point":
            self.annotations["point"].setdefault(cls, []).append((x, y))
        elif mode == "line":
            self.current_line.append((x, y))
            if len(self.current_line) == 2:
                self.annotations["line"].setdefault(cls, []).append(self.current_line.copy())
                self.current_line.clear()
        self.update_display()
    def mouse_move_event(self, event):
        x, y = self.get_mouse_pos(event)
        if self.dragging and self.selected:
            kind, cls, item, pt_idx = self.selected
            if kind == "point":
                self.annotations["point"][cls][item] = (x, y)
            elif kind == "line":
                self.annotations["line"][cls][item][pt_idx] = (x, y)
        else:
            self.hover = self.find_nearest_point(x, y)
        self.update_display()
    def mouse_release_event(self, event):
        self.dragging = False
        self.selected = None
    def try_delete_nearest(self, x, y, threshold=10):
        target = self.find_nearest_point(x, y, threshold)
        if not target:
            return
        kind, cls, item_idx, _ = target
        del self.annotations[kind][cls][item_idx]
        if not self.annotations[kind][cls]:
            del self.annotations[kind][cls]
        self.update_display()
    def find_nearest_point(self, x, y, threshold=10):
        for kind in ["point", "line"]:
            for cls, items in self.annotations[kind].items():
                for i, item in enumerate(items):
                    if kind == "point":
                        px, py = item
                        if abs(px - x) < threshold and abs(py - y) < threshold:
                            return (kind, cls, i, 0)
                    elif kind == "line":
                        for j, (px, py) in enumerate(item):
                            if abs(px - x) < threshold and abs(py - y) < threshold:
                                return (kind, cls, i, j)
        return None
    def get_color(self, name):
        h = int(hashlib.md5(name.encode()).hexdigest(), 16)
        hue = (h % 360) / 360.0
        r, g, b = colorsys.hsv_to_rgb(hue, 1.0, 1.0)
        return QColor(int(r * 255), int(g * 255), int(b * 255))
    def update_display(self):
        if not self.image:
            return
        pix = QPixmap(self.scaled_image)
        painter = QPainter(pix)
        painter.setFont(QFont("Arial", 10))
        for kind in ["point", "line"]:
            for cls, items in self.annotations[kind].items():
                color = self.get_color(cls)
                for i, item in enumerate(items):
                    if kind == "point":
                        x, y = [int(p * self.display_scale) for p in item]
                        pen = QPen(QColor("yellow") if self.hover == (kind, cls, i, 0) else color, 4)
                        painter.setPen(pen)
                        painter.drawEllipse(QPoint(x, y), 5, 5)
                        painter.drawText(x + 6, y + 6, cls)
                    elif kind == "line":
                        for j, (px, py) in enumerate(item):
                            sx, sy = int(px * self.display_scale), int(py * self.display_scale)
                            pen = QPen(QColor("yellow") if self.hover == (kind, cls, i, j) else color, 3)
                            painter.setPen(pen)
                            painter.drawEllipse(QPoint(sx, sy), 4, 4)
                        sx1, sy1 = int(item[0][0] * self.display_scale), int(item[0][1] * self.display_scale)
                        sx2, sy2 = int(item[1][0] * self.display_scale), int(item[1][1] * self.display_scale)
                        painter.setPen(QPen(color, 2))
                        painter.drawLine(QPoint(sx1, sy1), QPoint(sx2, sy2))
        if len(self.current_line) == 1:
            cx, cy = [int(p * self.display_scale) for p in self.current_line[0]]
            painter.setPen(QPen(QColor("blue"), 2))
            painter.drawEllipse(QPoint(cx, cy), 5, 5)
        painter.end()
        self.image_label.setPixmap(pix)
    def save_annotations(self):
        path, _ = QFileDialog.getSaveFileName(self, "–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏", "", "JSON (*.json)")
        if not path:
            return
        with open(path, "w") as f:
            json.dump(self.annotations, f, indent=2)
    def load_annotations(self):
        path, _ = QFileDialog.getOpenFileName(self, "–ó–∞–≥—Ä—É–∑–∏—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏", "", "JSON (*.json)")
        if not path:
            return
        with open(path, "r") as f:
            self.annotations = json.load(f)
        self.update_display()
    def add_class(self):
        cls = self.class_selector.currentText().strip()
        if cls and self.class_selector.findText(cls) == -1:
            self.class_selector.addItem(cls)
        self.class_selector.setCurrentText(cls)
if __name__ == "__main__":
    app = QApplication(sys.argv)
    tool = AnnotationTool()
    tool.show()
    sys.exit(app.exec_())
# ==== source/calibration/__init__.py ====
from .base import Calibration
from .pipeline import CalibrationPipeline
from calibration.refine.optimizer import RefineOptimizer
from .init.from_vp import VanishingPointCalibration
__all__ = [
    "Calibration",
    "CalibrationPipeline",
    "RefineOptimizer",
    "VanishingPointCalibration"
]
__version__ = "0.1.0"
__author__ = "–ê–∫–º—É—Ä–∑–∏–Ω –ú–∏—à–∞"
# ==== source/calibration/base.py ====
from abc import ABC, abstractmethod
import numpy as np
from core.camera import Camera
class Calibration(ABC):
    def __init__(self, camera: Camera = None, debug_save_path: str = None):
        self.camera = camera
        self.debug_save_path = debug_save_path
    @abstractmethod
    def run(self, data: dict, **kwargs) -> Camera:
        pass
    def compute_total_residuals(self, camera, data, params, residual_blocks):
        camera.set_params_from_list(params)
        residuals = []
        for block in residual_blocks:
            res = block(camera, data)
            residuals.extend(res)
        return np.array(residuals)
# ==== source/calibration/pipeline.py ====
from core.camera import Camera
from calibration.base import Calibration
class CalibrationPipeline:
    def __init__(self, stages: list[Calibration]):
        """
        :param init_stage: —ç—Ç–∞–ø –Ω–∞—á–∞–ª—å–Ω–æ–π –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏  –ø–æ —Ç–æ—á–∫–∞–º —Å—Ö–æ–¥–∞
        :param refine_stage: —ç—Ç–∞–ø —É—Ç–æ—á–Ω–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä—è–º–∞—è/–æ–±—Ä–∞—Ç–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
        """
        self.stages = stages
    def run(self, camera: Camera, data: dict, **kwargs) -> Camera:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—É—é –∫–∞–ª–∏–±—Ä–æ–≤–∫—É –∫–∞–º–µ—Ä—ã.
        :param camera: –æ–±—ä–µ–∫—Ç –∫–∞–º–µ—Ä—ã
        :param data: –¥–∞–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ç–∫–∏ (–Ω–∞–ø—Ä. {'angle': [...], 'parallel-1': [...]})
        :param kwargs: –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, error_func –∏–ª–∏ solver)
        """
        for idx, stage in enumerate(self.stages, 1):
            stage.camera = camera
            print("=" * 60)
            print(f"üîß [Pipeline] –≠—Ç–∞–ø {idx}: {stage.__class__.__name__}")
            print("=" * 60)
            camera = stage.run(data, **kwargs)
            print(f"‚úÖ [Pipeline] –≠—Ç–∞–ø {idx} –∑–∞–≤–µ—Ä—à—ë–Ω\n")
        print("üéØ [Pipeline] –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –∫–∞–º–µ—Ä—ã –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        print("=" * 60)
        print(f" [Pipeline] –ö–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è {[round(float(p), 2) for p in camera.get_params()]}")
        return camera
# ==== source/calibration/utils/__init__.py ====
from calibration.utils.data_preparation import load_lines, load_lines_from_json, \
    extract_direction_vectors_from_lines
from calibration.utils.gps_connection_world import gps_to_enu, enu_to_gps
from .plot_lines import draw_lines_on_image
__all__ = [
    "gps_to_enu",
    "enu_to_gps",
    "load_lines_from_json",
    "load_lines",
    "extract_direction_vectors_from_lines",
    "draw_lines_on_image"
]
# ==== source/calibration/utils/data_preparation.py ====
import numpy as np
import os
import json
from core.pointND import PointND
def load_data(path):
    lines = []
    with open(path, 'r') as file:
        for line in file:
            name, cords = line.split(':')
            points = eval(cords.strip())
            lines.append([PointND([x, y]) for x, y in points])
    return lines
def prep_data_angle(data):
    _data = []
    if len(data) % 2 == 0:
        for i in range(0, len(data), 2):
            _data.append(data[i] + data[i + 1])
        return np.array(_data)
    else:
        raise ValueError("–ö–æ–ª-–≤–æ –ª–∏–Ω–∏–π –Ω–µ —á–µ—Ç–Ω–æ–µ —á–∏—Å–ª–æ")
def prep_data_parallel(data):
    _data = []
    for i in range(0, len(data) - 1):
        _data.append(data[i] + data[i + 1])
    return np.array(_data)
def load_params(path):
    with open(path, 'r') as file:
        return [float(value) for value in file.readline().split()]
def prep_data_back_to_reverse(camera, data):
    data = np.array(data)
    data_calc = []
    for start, end in data:
        start_3d = camera.back_crop(start)
        end_3d = camera.back_crop(end)
        data_calc.append([camera.direct_crop(start_3d), camera.direct_crop(end_3d)])
    return np.array(data_calc)
def fun_lines(x, start: PointND, end: PointND, orthogonal=False):
    x1, y1 = start.get()
    x2, y2 = end.get()
    if not orthogonal:
        return (x - x1) * (y2 - y1) / (x2 - x1) + y1
    else:
        m = (y2 - y1) / (x2 - x1)
        return (-1 / m) * (x - x1) + y1
def load_lines(filename):
    if not os.path.exists(filename):
        print("–§–∞–π–ª –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return
    with open(filename, "r") as f:
        data = json.load(f)
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫–∏ –∫–ª—é—á–µ–π –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å–ø–∏—Å–æ–∫ –ª–∏–Ω–∏–π
    lines = [[tuple(point) for point in line] for line in data.values()]
    return lines
import json
def load_lines_from_json(filepath: str):
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    lines = []
    for item in data:
        gps_start = item['start']['gps']
        gps_end = item['end']['gps']
        pix_start = item['start']['pixel']
        pix_end = item['end']['pixel']
        line = {
            'gps': [gps_start, gps_end],  # [[lat1, lon1], [lat2, lon2]]
            'pixel': [pix_start, pix_end],  # [[x1, y1], [x2, y2]]
        }
        lines.append(line)
    return lines
def extract_direction_vectors_from_lines(lines):
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–ø–∏—Å–æ–∫ –ª–∏–Ω–∏–π, –∑–∞–¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–∏ —Ç–æ—á–µ–∫ [(x1, y1), (x2, y2)],
    –≤ –Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª—è—é—â–∏–µ –≤–µ–∫—Ç–æ—Ä—ã [dx, dy].
    """
    direction_vectors = []
    for (x1, y1), (x2, y2) in lines:
        dx = x2 - x1
        dy = y2 - y1
        direction = np.array([dx, dy], dtype=np.float64)
        norm = np.linalg.norm(direction)
        if norm > 1e-6:  # –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω—É–ª–µ–≤—É—é –¥–ª–∏–Ω—É
            direction_vectors.append(direction / norm)
    return direction_vectors# ==== source/calibration/utils/gps_connection_world.py ====
import numpy as np
from pyproj import Geod
def gps_to_enu(lat, lon, ref_lat, ref_lon):
    """
    –ü–µ—Ä–µ–≤–æ–¥ GPS (—à–∏—Ä–æ—Ç–∞, –¥–æ–ª–≥–æ—Ç–∞) –≤ –ª–æ–∫–∞–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã ENU (–≤ –º–µ—Ç—Ä–∞—Ö)
    """
    geod = Geod(ellps="WGS84")
    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –∏ –∞–∑–∏–º—É—Ç –¥–æ —Ç–æ—á–∫–∏
    azimuth, _, distance = geod.inv(ref_lon, ref_lat, lon, lat)
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã ENU
    east = distance * np.sin(np.deg2rad(azimuth))
    north = distance * np.cos(np.deg2rad(azimuth))
    return east, north
def enu_to_gps(east, north, ref_lat, ref_lon):
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã ENU (–≤ –º–µ—Ç—Ä–∞—Ö)
    –æ–±—Ä–∞—Ç–Ω–æ –≤ GPS-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (—à–∏—Ä–æ—Ç–∞, –¥–æ–ª–≥–æ—Ç–∞).
    Parameters:
    -----------
    east : float
        –°–º–µ—â–µ–Ω–∏–µ –Ω–∞ –≤–æ—Å—Ç–æ–∫ (–≤ –º–µ—Ç—Ä–∞—Ö)
    north : float
        –°–º–µ—â–µ–Ω–∏–µ –Ω–∞ —Å–µ–≤–µ—Ä (–≤ –º–µ—Ç—Ä–∞—Ö)
    ref_lat : float
        –ù–∞—á–∞–ª—å–Ω–∞—è —à–∏—Ä–æ—Ç–∞ (–≥—Ä–∞–¥—É—Å—ã)
    ref_lon : float
        –ù–∞—á–∞–ª—å–Ω–∞—è –¥–æ–ª–≥–æ—Ç–∞ (–≥—Ä–∞–¥—É—Å—ã)
    Returns:
    --------
    lat : float
        –ù–æ–≤–∞—è —à–∏—Ä–æ—Ç–∞
    lon : float
        –ù–æ–≤–∞—è –¥–æ–ª–≥–æ—Ç–∞
    """
    geod = Geod(ellps="WGS84")
    # –í—ã—á–∏—Å–ª—è–µ–º –∞–∑–∏–º—É—Ç –∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
    distance = np.hypot(east, north)
    azimuth = np.rad2deg(np.arctan2(east, north))
    # –ü—Ä—è–º–∞—è –≥–µ–æ–¥–µ–∑–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞
    lon, lat, _ = geod.fwd(ref_lon, ref_lat, azimuth, distance)
    return lat, lon
# ==== source/calibration/utils/plot_lines.py ====
import cv2
import matplotlib.pyplot as plt
from .data_preparation import load_lines
def draw_lines_on_image(image_path, lines, line_color=(0, 0, 255), thickness=2):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –æ—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç –Ω–∞ –Ω—ë–º –∑–∞–¥–∞–Ω–Ω—ã–µ –ª–∏–Ω–∏–∏.
    """
    image = cv2.imread(image_path)
    if image is None:
        raise FileNotFoundError(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {image_path}")
    for pt1, pt2 in lines:
        cv2.line(image, pt1, pt2, line_color, thickness)
    return image
if __name__ == "__main__":
    lines = load_lines('marked/horizontal_lines_all.json')
    image_with_lines = draw_lines_on_image('image/pattern_corrected_image.png', lines)
    plt.imshow(cv2.cvtColor(image_with_lines, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.title("–õ–∏–Ω–∏–∏, –Ω–∞–ª–æ–∂–µ–Ω–Ω—ã–µ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
    plt.show()
# ==== source/calibration/debug/__init__.py ====
from .debug_vp import visualize_vps_debug
from .debug_scene import visualize_grid_debug, load_scene_gps, visualize_grid_gps_debug, set_grid_real
from .debug_source import visualize_source
__all__ = [
    "visualize_vps_debug",
    "visualize_grid_debug",
    "visualize_grid_gps_debug",
    "visualize_source",
    "load_scene_gps",
    "set_grid_real"
]
# ==== source/calibration/debug/debug_position_camera.py ====
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
from sympy.physics.units import length
from core import Camera, PointND
def visualize_camera_and_world_axes(
        camera: Camera
):
    """
    –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∫–∞–º–µ—Ä—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –º–∏—Ä–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    """
    R = camera.extrinsics.get_rotation().T
    C = camera.extrinsics.get_position()
    x_cam = R[:, 0]  # –≤–ø—Ä–∞–≤–æ
    y_cam = R[:, 1]  # –≤–≤–µ—Ä—Ö
    z_cam = R[:, 2]  # –≤–∑–≥–ª—è–¥
    scale = 10
    fig = plt.figure(figsize=(8, 8))
    ax = fig.add_subplot(111, projection='3d')
    # –û—Å–∏ –º–∏—Ä–∞ –∏–∑ –Ω–∞—á–∞–ª–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    ax.quiver(0, 0, 0, 1, 0, 0, length=scale, color='red', label='World X')
    ax.quiver(0, 0, 0, 0, 1, 0, length=scale, color='green', label='World Y')
    ax.quiver(0, 0, 0, 0, 0, 1, length=scale, color='blue', label='World Z')
    ax.quiver(*C, *x_cam, length=scale, color='r', linestyle='dashed', label='Camera X')
    ax.quiver(*C, *y_cam, length=scale, color='g', linestyle='dashed', label='Camera Y')
    ax.quiver(*C, *z_cam, length=scale, color='b', linestyle='dashed', label='Camera Z')
    ax.scatter(*C, label='C')
    ax.scatter(*-R @ C, label='- R @ C')
    point_start = PointND([960, 540])
    plane_z = 0
    grid_range = 10
    grid_step = 1
    anchor_3D = camera.project_back(point_start, plane_z=plane_z)
    anchor_x, anchor_y, anchor_z = anchor_3D.get()
    to_scene = anchor_3D.get() - C
    if np.dot(R[:, 2], to_scene) < 0:
        print("–ö–∞–º–µ—Ä–∞ —Å–º–æ—Ç—Ä–∏—Ç –≤ –æ–±—Ä–∞—Ç–Ω—É—é —Å—Ç–æ—Ä–æ–Ω—É ‚Äî Z –Ω—É–∂–Ω–æ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å")
    # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤ –≤ —Å–µ—Ç–∫–µ
    count = int(2 * grid_range / grid_step) + 1
    world_points = []
    for i in range(count):
        for j in range(count):
            x = anchor_x - grid_range + i * grid_step
            y = anchor_y - grid_range + j * grid_step
            world_points.append(PointND(np.array([x, y, plane_z])))
    for i in range(count):
        for j in range(count - 1):
            p1 = world_points[i * count + j].get()
            p2 = world_points[i * count + (j + 1)].get()
            ax.plot([p1[0], p2[0]], [p1[1], p2[1]], color='blue', linewidth=1)
    for j in range(count):
        for i in range(count - 1):
            p1 = world_points[i * count + j].get()
            p2 = world_points[(i + 1) * count + j].get()
            ax.plot([p1[0], p2[0]], [p1[1], p2[1]], color='blue', linewidth=1)
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('Z')
    ax.set_title('–ö–∞–º–µ—Ä–∞ –∏ –º–∏—Ä–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç')
    ax.legend()
    plt.tight_layout()
    plt.show()
camera = Camera("../../../example/pushkin_aksakov/image/pattern_corrected_image.png")
camera.set_params_from_list([1230, -13.46, 48.12, -164.54, 0, 0, 10])
# camera.set_params_from_list([1246.66, -142.93, 49.25, 173.98, -10.02, -15.42, 27.31])
visualize_camera_and_world_axes(camera)
# ==== source/calibration/debug/debug_scene.py ====
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.lines as mlines
from pyproj import Proj, transform
import requests
from PIL import Image
from io import BytesIO
from core import Camera, PointND
from calibration.utils import enu_to_gps
def visualize_grid_debug(
        camera: Camera,
        point_start: PointND,
        grid_range: float = 5.0,  # –¥–∏–∞–ø–∞–∑–æ–Ω –≤ –º–µ—Ç—Ä–∞—Ö –æ—Ç —Ü–µ–Ω—Ç—Ä–∞
        grid_step: float = 1.0,  # —Ä–∞–∑–º–µ—Ä –∫–ª–µ—Ç–∫–∏
        arrow_len: float = 5.0,  # –¥–ª–∏–Ω–∞ –≤–µ–∫—Ç–æ—Ä–∞ "–≤–≤–µ—Ä—Ö"
        plane_z: float = 0.0,  # –ø–ª–æ—Å–∫–æ—Å—Ç—å, –Ω–∞ –∫–æ—Ç–æ—Ä—É—é –∫–ª–∞–¥—ë–º —Å–µ—Ç–∫—É
        save_path=None
):
    image = camera.get_image()
    height, width = image.shape[:2]
    fig, ax = plt.subplots(figsize=(12, 7))
    ax.set_title("–ö–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–∞—è —Å–µ—Ç–∫–∞ (1√ó1 –º) –≤ –ø—Ä–æ–µ–∫—Ü–∏–∏")
    ax.set_xlim(0, width)
    ax.set_ylim(height, 0)
    plt.imshow(image)
    plt.scatter(*point_start.get(),c='red')
    anchor_3D = camera.project_back(point_start, plane_z=plane_z)
    anchor_x, anchor_y, anchor_z = anchor_3D.get()
    # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤ –≤ —Å–µ—Ç–∫–µ
    count, world_points = set_grid_real(anchor_x, anchor_y, grid_range, grid_step, plane_z)
    for i in range(count):
        for j in range(count - 1):
            p1 = world_points[i * count + j]
            p2 = world_points[i * count + (j + 1)]
            p1_proj = camera.project_direct(p1).get()
            p2_proj = camera.project_direct(p2).get()
            ax.plot([p1_proj[0], p2_proj[0]], [p1_proj[1], p2_proj[1]], color='blue', linewidth=1)
    for j in range(count):
        for i in range(count - 1):
            p1 = world_points[i * count + j]
            p2 = world_points[(i + 1) * count + j]
            p1_proj = camera.project_direct(p1).get()
            p2_proj = camera.project_direct(p2).get()
            ax.plot([p1_proj[0], p2_proj[0]], [p1_proj[1], p2_proj[1]], color='blue', linewidth=1)
    def draw_arrow_from_3D(p3D):
        base = camera.project_direct(p3D).get()
        tip_point = PointND(p3D.get() + np.array([0, 0, arrow_len]))
        tip = camera.project_direct(tip_point).get()
        # –∫—Ä–∞—Å–Ω–∞—è —Ç–æ—á–∫–∞ ‚Äî –æ—Å–Ω–æ–≤–∞–Ω–∏–µ
        ax.scatter(base[0], base[1], color='red', s=10, zorder=3)
        # —á—ë—Ä–Ω–∞—è —Å—Ç—Ä–µ–ª–∫–∞ ‚Äî –≤–≤–µ—Ä—Ö
        ax.annotate(
            '', xy=(tip[0], tip[1]), xytext=(base[0], base[1]),
            arrowprops=dict(arrowstyle='->', color='black', lw=1.5),
            annotation_clip=False, label=f'–í—ã—Å–æ—Ç–∞: {arrow_len}'
        )
    top_left = world_points[0]
    top_right = world_points[count - 1]
    bottom_left = world_points[(count - 1) * count]
    bottom_right = world_points[-1]
    for corner in [top_left, top_right, bottom_left, bottom_right]:
        draw_arrow_from_3D(corner)
    draw_coordinate_system_overlay(camera, ax, scale=10)
    arrow_legend = mlines.Line2D([], [], color='black', marker=r'$\uparrow$', linestyle='None',
                                 markersize=10, label=f'–í–µ–∫—Ç–æ—Ä –≤–≤–µ—Ä—Ö ({arrow_len} –º)')
    ax.legend(handles=[arrow_legend])
    if save_path is not None:
        plt.savefig(save_path)
    plt.show()
def set_grid_real(anchor_x, anchor_y, grid_range, grid_step, plane_z):
    count = int(2 * grid_range / grid_step) + 1
    world_points = []
    for i in range(count):
        for j in range(count):
            x = anchor_x - grid_range + i * grid_step
            y = anchor_y - grid_range + j * grid_step
            world_points.append(PointND(np.array([x, y, plane_z])))
    return count, world_points
def draw_coordinate_system_overlay(camera: Camera, ax, scale=10):
    origin = PointND([0, 0, 0, 1])
    X = PointND([scale, 0, 0, 1])
    Y = PointND([0, scale, 0, 1])
    Z = PointND([0, 0, scale, 1])
    p0 = camera.project_direct(origin).get()
    print(f'–ü–∏–∫—Å–µ–ª—å –º–∏—Ä–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: {p0}')
    px = camera.project_direct(X).get()
    py = camera.project_direct(Y).get()
    pz = camera.project_direct(Z).get()
    def draw_arrow(p_start, p_end, color, label):
        ax.annotate('', xy=p_end[:2], xytext=p_start[:2],
                    arrowprops=dict(arrowstyle='->', linewidth=2, color=color))
        ax.text(p_end[0], p_end[1], label, color=color,
                fontsize=12, fontweight='bold', ha='center', va='center')
    draw_arrow(p0, px, 'red', 'X')
    draw_arrow(p0, py, 'green', 'Y')
    draw_arrow(p0, pz, 'blue', 'Z')
def visualize_coordinate_system(camera: Camera, save_path: str):
    image = camera.get_image()
    scale = 10  # –¥–ª–∏–Ω–∞ –æ—Å–µ–π –≤ —É—Å–ª–æ–≤–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü–∞—Ö
    # –¢–æ—á–∫–∏ –≤ –º–∏—Ä–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    origin = PointND([0, 0, 0, 1])
    X = PointND([scale, 0, 0, 1])
    Y = PointND([0, scale, 0, 1])
    Z = PointND([0, 0, scale, 1])
    # –ü—Ä–æ–µ–∫—Ü–∏—è –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    p0 = camera.project_direct(origin).get()
    px = camera.project_direct(X).get()
    py = camera.project_direct(Y).get()
    pz = camera.project_direct(Z).get()
    # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —á–µ—Ä–µ–∑ matplotlib
    fig, ax = plt.subplots(figsize=(10, 10))
    ax.imshow(image)
    ax.axis('off')
    def draw_arrow(p_start, p_end, color, label):
        ax.annotate(
            '', xy=p_end[:2], xytext=p_start[:2],
            arrowprops=dict(arrowstyle='->', linewidth=2, color=color)
        )
        ax.text(p_end[0], p_end[1], label, color=color,
                fontsize=12, fontweight='bold', ha='center', va='center')
    draw_arrow(p0, px, 'red', 'X')
    draw_arrow(p0, py, 'green', 'Y')
    draw_arrow(p0, pz, 'blue', 'Z')
    plt.savefig(save_path, bbox_inches='tight', pad_inches=0)
def load_scene_gps(lon, lat, save_path=None, zoom=19, size=(650, 450)):
    # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    url = f"https://static-maps.yandex.ru/1.x/?ll={lon},{lat}&z={zoom}&l=sat&size={size[0]},{size[1]}"
    response = requests.get(url)
    image = Image.open(BytesIO(response.content))
    if save_path is not None:
        image.save(save_path)
    return image
# todo –ø–µ—Ä–µ–¥–∞–ª–∞—Ç—å
def gps_to_pixel(lat, lon, ref_lat, ref_lon, img_width, img_height, meters_per_pixel=0.3):
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç GPS –≤ –ø–∏–∫—Å–µ–ª–∏, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—è, —á—Ç–æ ref_lat/lon –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ü–µ–Ω—Ç—Ä–µ.
    """
    from pyproj import Geod
    geod = Geod(ellps="WGS84")
    def meters_per_pixel(zoom, lat):
        return 156543.03392 * np.cos(np.deg2rad(lat)) / (2 ** zoom)
    # –°–º–µ—â–µ–Ω–∏–µ –Ω–∞ –≤–æ—Å—Ç–æ–∫ –∏ —Å–µ–≤–µ—Ä (–≤ –º–µ—Ç—Ä–∞—Ö)
    az_east, _, east = geod.inv(ref_lon, ref_lat, lon, ref_lat)
    az_north, _, north = geod.inv(ref_lon, ref_lat, ref_lon, lat)
    if lat < ref_lat:
        north = -north
    if lon < ref_lon:
        east = -east
    x = img_width / 2 + east / meters_per_pixel
    y = img_height / 2 - north / meters_per_pixel  # —Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑
    return x, y
def visualize_grid_gps_debug(
        camera: Camera,
        point_start: PointND,
        gps_origin: tuple,
        grid_range: float = 10.0,  # –¥–∏–∞–ø–∞–∑–æ–Ω –≤ –º–µ—Ç—Ä–∞—Ö –æ—Ç —Ü–µ–Ω—Ç—Ä–∞
        grid_step: float = 1.0,  # —Ä–∞–∑–º–µ—Ä –∫–ª–µ—Ç–∫–∏
        plane_z: float = 0.0,  # –ø–ª–æ—Å–∫–æ—Å—Ç—å, –Ω–∞ –∫–æ—Ç–æ—Ä—É—é –∫–ª–∞–¥—ë–º —Å–µ—Ç–∫—É
        save_path=None
):
    ref_lat, ref_lon = gps_origin
    image = load_scene_gps(ref_lon, ref_lat, zoom=19)
    image_np = np.array(image)
    height, width = image_np.shape[:2]
    fig, ax = plt.subplots(figsize=(10, 10))
    ax.imshow(image_np)
    ax.set_title("ENU-—Å–µ—Ç–∫–∞ –Ω–∞ —Å–ø—É—Ç–Ω–∏–∫–µ")
    anchor_3D = camera.project_back(point_start, plane_z=plane_z)
    anchor_x, anchor_y, anchor_z = anchor_3D.get()
    count, world_points = set_grid_real(anchor_x, anchor_y, grid_range, grid_step, plane_z)  # enu
    for i in range(count):
        for j in range(count - 1):
            world_point_1 = world_points[i * count + j]
            world_point_2 = world_points[i * count + j + 1]
            east1, north1 = world_point_1.get()[:2]
            east2, north2 = world_point_2.get()[:2]
            lat1, lon1 = enu_to_gps(east1, north1, ref_lat, ref_lon)
            lat2, lon2 = enu_to_gps(east2, north2, ref_lat, ref_lon)
            px1, py1 = gps_to_pixel(lat1, lon1, ref_lat, ref_lon, width, height)
            px2, py2 = gps_to_pixel(lat2, lon2, ref_lat, ref_lon, width, height)
            ax.plot([px1, px2], [py1, py2], color='red')
    for j in range(count):
        for i in range(count - 1):
            world_point_1 = world_points[i * count + j]
            world_point_2 = world_points[(i + 1) * count + j]
            east1, north1 = world_point_1.get()[:2]
            east2, north2 = world_point_2.get()[:2]
            lat1, lon1 = enu_to_gps(east1, north1, ref_lat, ref_lon)
            lat2, lon2 = enu_to_gps(east2, north2, ref_lat, ref_lon)
            px1, py1 = gps_to_pixel(lat1, lon1, ref_lat, ref_lon, width, height)
            px2, py2 = gps_to_pixel(lat2, lon2, ref_lat, ref_lon, width, height)
            ax.plot([px1, px2], [py1, py2], color='red')
    plt.show()
# ==== source/calibration/debug/debug_source.py ====
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import hashlib
import numpy as np
def visualize_source(data: dict, image=None):
    """
    data: {
        "group1": [ [(x1,y1), (x2,y2)], ... ],
        "group2": [ [(x1,y1), (x2,y2)], ... ],
    }
    image: optional background image (e.g. from camera.get_image())
    """
    fig, ax = plt.subplots()
    if image is not None:
        ax.imshow(image)
    for key, lines in data.items():
        color = get_color_by_key(key)
        for i, (p1, p2) in enumerate(lines):
            ax.plot([p1[0], p2[0]], [p1[1], p2[1]], color=color, linewidth=2)
            ax.scatter(*p1, color=color, s=10)
            ax.scatter(*p2, color=color, s=10)
        # –¥–æ–±–∞–≤–∏–º –ª–∏–Ω–∏—é –≤ –ª–µ–≥–µ–Ω–¥—É –æ–¥–∏–Ω —Ä–∞–∑
        ax.plot([], [], color=color, label=key)
    ax.legend(loc='upper right')
    ax.axis('equal')
    plt.tight_layout()
    plt.show()
def get_color_by_key(key):
    """–£–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ü–≤–µ—Ç –ø–æ –∏–º–µ–Ω–∏ –≥—Ä—É–ø–ø—ã"""
    cmap = cm.get_cmap('tab10')
    hash_val = int(hashlib.md5(key.encode()).hexdigest(), 16)
    return cmap(hash_val % 10)
# ==== source/calibration/debug/debug_vp.py ====
import matplotlib.pyplot as plt
import numpy as np
import cv2
def draw_coordinate_axes_from_vps(
        vanishing_points,
        center,
        scale=100,
        labels=None,
        colors=None,
        flip_z=True,
        image=None,
        save_path=None,
        ax=None
):
    if labels is None:
        labels = ['X', 'Y', 'Z']
    if colors is None:
        colors = ['red', 'green', 'blue']
    cx, cy = center
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ—Å–µ–π
    if ax is None:
        fig, ax = plt.subplots()
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ñ–æ–Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    if image is not None:
        ax.imshow(image)
    # –†–∏—Å—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–Ω—ã–µ –æ—Å–∏
    for i, (x, y) in enumerate(vanishing_points):
        dx = x - cx
        dy = y - cy
        norm = np.hypot(dx, dy)
        dx_scaled = dx / norm * scale
        dy_scaled = dy / norm * scale
        if flip_z and labels[i].upper() == 'Z':
            dx_scaled *= -1
            dy_scaled *= -1
        ax.arrow(cx, cy, dx_scaled, dy_scaled,
                 color=colors[i], width=1.2, head_width=10, length_includes_head=True)
        ax.text(cx + dx_scaled * 1.1, cy + dy_scaled * 1.1,
                labels[i], fontsize=12, color=colors[i], weight='bold')
    ax.set_title("Coordinate Axes from Vanishing Points")
    ax.axis('off')
    if save_path:
        plt.savefig(save_path, dpi=150)
def visualize_vps_debug(
        camera,
        step_x=400,
        step_y=300,
        scale=100,
        save_path=None,
        show=False,
        flip_z=True,
        dpi=200
):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–Ω—ã–µ –æ—Å–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∫–∞–º–µ—Ä—ã –ø–æ —Ç–æ—á–∫–∞–º —Å—Ö–æ–¥–∞.
    :param camera: –æ–±—ä–µ–∫—Ç –∫–∞–º–µ—Ä—ã —Å –º–µ—Ç–æ–¥–æ–º get_image(), intrinsics.get(), extrinsics.get_rotation()
    :param step_x: —à–∞–≥ —Å–µ—Ç–∫–∏ –ø–æ –æ—Å–∏ X (–≤ –ø–∏–∫—Å–µ–ª—è—Ö)
    :param step_y: —à–∞–≥ —Å–µ—Ç–∫–∏ –ø–æ –æ—Å–∏ Y (–≤ –ø–∏–∫—Å–µ–ª—è—Ö)
    :param scale: –¥–ª–∏–Ω–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–Ω—ã—Ö —Å—Ç—Ä–µ–ª–æ–∫
    :param save_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    :param show: –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ –æ–∫–Ω–æ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
    :param flip_z: –æ—Ç—Ä–∞–∂–∞—Ç—å –ª–∏ –æ—Å—å Z
    :param dpi: —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    """
    image = camera.get_image()
    K = camera.intrinsics.get()
    R = camera.extrinsics.get_rotation()
    # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º —Ç–æ—á–∫–∏ —Å—Ö–æ–¥–∞ –∏–∑ R –∏ K
    vp1 = K @ R[:, 0]
    vp2 = K @ R[:, 1]
    vp3 = K @ R[:, 2]
    vp1 = vp1[:2] / vp1[2]
    vp2 = vp2[:2] / vp2[2]
    vp3 = vp3[:2] / vp3[2]
    vps = np.array([vp1, vp2, vp3])
    h, w = image.shape[:2]
    centers = [
        (int(x), int(y))
        for y in np.arange(step_y, h, step_y)
        for x in np.arange(step_x, w, step_x)
    ]
    fig, ax = plt.subplots(figsize=(12, 8))
    ax.imshow(image)
    for center in centers:
        draw_coordinate_axes_from_vps(
            vanishing_points=vps,
            center=center,
            scale=scale,
            flip_z=flip_z,
            ax=ax
        )
    ax.set_title("Vanishing Point Coordinate Axes")
    ax.axis('off')
    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=dpi, bbox_inches='tight')
        print(f"[DEBUG] Saved visualization to {save_path}")
    if show:
        plt.show()
    else:
        plt.close(fig)
# ==== source/calibration/refine/__init__.py ====
from .optimizer import RefineOptimizer
from .back_error_funk import residual_interline_distance, residual_parallel_group, residual_vertical_lines_directional
from .direct_error_funk import residual_reprojection_line
__all__ = [
    "RefineOptimizer",
    "residual_interline_distance",
    "residual_parallel_group",
    "residual_reprojection_line",
    "residual_vertical_lines_directional"
]
# ==== source/calibration/refine/back_error_funk.py ====
import numpy as np
from core import Camera, PointND
def residual_interline_distance(camera, data, group, expected):
    residuals = []
    lines = data.get(group, [])
    for i in range(len(lines) - 1):
        d = compute_interline_distance(camera, lines[i], lines[i + 1])
        residuals.append(d - expected)
    return residuals
def compute_interline_distance(camera: Camera, line1, line2, plane_z=0):
    c1 = PointND(np.mean(line1, axis=0))
    c2 = PointND(np.mean(line2, axis=0))
    X1 = camera.project_back(c1, plane_z).get()
    X2 = camera.project_back(c2, plane_z).get()
    # –∞–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä—É–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ –ø–µ—Ä–≤–æ–π –ª–∏–Ω–∏–∏
    P1a = camera.project_back(PointND(line1[0]), plane_z).get()
    P1b = camera.project_back(PointND(line1[1]), plane_z).get()
    direction = P1b - P1a
    direction = direction[:2] / np.linalg.norm(direction[:2])
    normal = np.array([-direction[1], direction[0]])  # –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ –≤ 2D
    # –ø—Ä–æ–µ—Ü–∏—Ä—É–µ–º —Ä–∞–∑–Ω–æ—Å—Ç—å —Ç–æ—á–µ–∫ –Ω–∞ –Ω–æ—Ä–º–∞–ª—å
    delta = (X2 - X1)[:2]
    dist = np.abs(np.dot(delta, normal))
    return dist
def residual_parallel_group(camera, data, group, plane_z=0):
    """
    –†–µ–∑–∏–¥—É–∞–ª: –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –≤—Å–µ –ª–∏–Ω–∏–∏ –≤ –≥—Ä—É–ø–ø–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã –≤ –º–∏—Ä–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç.
    –û—à–∏–±–∫–∞ = –∫–æ—Å–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª—è—é—â–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤.
    :param camera: –º–æ–¥–µ–ª—å –∫–∞–º–µ—Ä—ã
    :param data: —Å–ª–æ–≤–∞—Ä—å —Å –ª–∏–Ω–∏—è–º–∏
    :param group: –∏–º—è –∫–ª—é—á–∞ –≤ data
    :param plane_z: –ø–ª–æ—Å–∫–æ—Å—Ç—å –æ–±—Ä–∞—Ç–Ω–æ–π –ø—Ä–æ–µ–∫—Ü–∏–∏
    :return: —Å–ø–∏—Å–æ–∫ residuals
    """
    residuals = []
    lines = data.get(group, [])
    if len(lines) < 2:
        return residuals  # –Ω–µ—á–µ–≥–æ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å
    # –≤—ã—á–∏—Å–ª—è–µ–º 3D-–Ω–∞–ø—Ä–∞–≤–ª—è—é—â–∏–µ
    directions = []
    for p1, p2 in lines:
        X1 = camera.project_back(PointND(p1), plane_z).get()
        X2 = camera.project_back(PointND(p2), plane_z).get()
        d = X2 - X1
        norm = np.linalg.norm(d)
        if norm < 1e-6:
            continue  # –≤—ã—Ä–æ–∂–¥–µ–Ω–Ω–∞—è
        directions.append(d[:2] / norm)  # —Ç–æ–ª—å–∫–æ XY-–ø–ª–æ—Å–∫–æ—Å—Ç—å
    if len(directions) < 2:
        return residuals  # –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π
    # —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å –ø–µ—Ä–≤–æ–π
    ref = directions[0]
    for d in directions[1:]:
        cross = np.cross(ref, d)  # ‚Üí 0, –µ—Å–ª–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã
        residuals.append(cross)
    return residuals
def residual_vertical_lines_directional(camera, data, group):
    residuals = []
    lines = data.get(group, [])
    for p1, p2 in lines:
        X1 = camera.project_back(PointND(p1), 0).get()
        X2 = camera.project_back(PointND(p2), 1).get()
# ==== source/calibration/refine/direct_error_funk.py ====
import numpy as np
from core import Camera, PointND
from calibration.utils import gps_to_enu
def residual_reprojection_line(camera, data, group, gps_origin):
    residuals = []
    lines = data.get(group, [])
    for line in lines:
        p1, p2 = line['pixel']
        P1, P2 = line['gps']
        _p1 = camera.project_direct(PointND([*gps_to_enu(*P1, *gps_origin), 0])).get()
        _p2 = camera.project_direct(PointND([*gps_to_enu(*P2, *gps_origin), 0])).get()
        error1 = np.sum((np.array(_p2) - np.array(p2)) ** 2)
        error2 = np.sum((np.array(_p1) - np.array(p1)) ** 2)
        error = np.sqrt(error1 + error2)
        residuals.append(error)
    return residuals
def line_projection_error(camera: Camera, line, gps_origin):
    p1, p2 = line['pixel']
    P1, P2 = line['gps']
    P1, P2 = gps_to_enu(*gps_origin, *P1)
    return 0
def point_projection_error(camera: Camera, point) -> float:
    point2D, point3D = point
    proj2D = camera.project_direct(point3D)
    return np.linalg.norm(point2D.get() - proj2D.get())
# ==== source/calibration/refine/optimizer.py ====
import numpy as np
from pandas.core.methods.selectn import SelectNSeries
from scipy.optimize import least_squares
from calibration.base import Calibration
from core.camera import Camera
from core.pointND import PointND
class RefineOptimizer(Calibration):
    def __init__(self, camera: Camera,
                 residual_blocks: list,
                 bounds: tuple = None,
                 solver=least_squares,
                 method: str = "trf",
                 mask: list = None,
                 debug_save_path: str = None,
                 gps_origin: tuple = None,
                 ):
        super().__init__(camera, debug_save_path)
        self.residual_blocks = residual_blocks
        self.bounds = bounds if bounds is not None else ([800, -360, -360, -360, -30, -30, 5],
                                                         [2000, 360, 360, 360, 30, 30, 30])
        self.mask = mask if mask is not None else [0, 1, 2, 3, 4, 5, 6]
        self.solver = solver
        self.method = method
        self.gps_origin = gps_origin
    def run(self, data, **kwargs) -> Camera:
        """
        :param data: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
        :return: –æ–±–Ω–æ–≤–ª—ë–Ω–Ω–∞—è –∫–∞–º–µ—Ä–∞
        """
        print("=" * 50)
        print("üîß [RefineOptimizer] –ó–∞–ø—É—Å–∫ –¥–æ–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–∞–º–µ—Ä—ã")
        print("=" * 50)
        full_params = np.array(self.camera.get_params(), dtype=float)
        print(f"üìå –ù–∞—á–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {np.round(full_params, 2).tolist()}")
        x0 = full_params[self.mask]
        def loss_fn(masked_params):
            current_params = full_params.copy()
            current_params[self.mask] = masked_params
            return self.compute_total_residuals(self.camera, data, current_params, self.residual_blocks)
        if self.method == "lm":
            result = self.solver(loss_fn,
                                 x0,
                                 method=self.method,
                                 verbose=2,
                                 max_nfev=10000
                                 )
        else:
            result = self.solver(loss_fn,
                                 x0,
                                 method=self.method,
                                 bounds=self.bounds,
                                 verbose=2,
                                 max_nfev=3000,
                                 gtol=1e-8,
                                 xtol=1e-8,
                                 ftol=1e-8
                                 )
        print("-" * 50)
        print(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        print(f"üîÅ –ò—Ç–µ—Ä–∞—Ü–∏–π: {result.nfev}")
        print(f"üéØ –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞ (cost): {result.cost:.6f}")
        print("üìç –û–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:", np.round(result.x, 2).tolist())
        full_params[self.mask] = result.x
        self.camera.set_params_from_list(full_params)
        if self.debug_save_path is not None:
            from calibration.debug import visualize_grid_debug, visualize_grid_gps_debug
            point_start = PointND(self.camera.intrinsics.get_main_point(), add_weight=True)
            visualize_grid_debug(self.camera, point_start, save_path=self.debug_save_path + "grid.png",grid_range=10)
            # visualize_grid_gps_debug(self.camera, point_start, gps_origin=self.gps_origin)
            if self.gps_origin is not None:
                pass
        return self.camera
# ==== source/calibration/init/__init__.py ====
from .from_vp import VanishingPointCalibration
__all__ = [
    "VanishingPointCalibration"
]# ==== source/calibration/init/from_vp.py ====
import numpy as np
from calibration.base import Calibration
from source.core import Camera, PointND
class VanishingPointCalibration(Calibration):
    def __init__(self, camera: Camera, debug_save_path: str = None):
        super().__init__(camera, debug_save_path)
        self.vpX = None  # —Ç–æ—á–∫–∞ —Å—Ö–æ–¥–∞ –ø–æ –æ—Å–∏ X (–≥–æ—Ä–∏–∑–æ–Ω—Ç)
        self.vpY = None  # —Ç–æ—á–∫–∞ —Å—Ö–æ–¥–∞ –ø–æ –æ—Å–∏ Y (–≥–æ—Ä–∏–∑–æ–Ω—Ç)
        self.vpZ = None  # —Ç–æ—á–∫–∞ —Å—Ö–æ–¥–∞ –ø–æ –æ—Å–∏ Z (–≤–µ—Ä—Ç–∏–∫–∞–ª—å)
    def set_vanishing_points(self, vpX, vpY=None, vpZ=None):
        self.vpX = np.array(vpX, dtype=float)
        if vpY is not None:
            self.vpY = np.array(vpY, dtype=float)
        if vpZ is not None:
            self.vpZ = np.array(vpZ, dtype=float)
    def calc_f(self):
        cx, cy = self.camera.intrinsics.get_main_point()
        c = np.array([cx, cy, 1.0])
        if self.vpX is not None and self.vpZ is not None:
            v1 = np.append(self.vpX, 1.0)
            v2 = np.append(self.vpZ, 1.0)
            term = np.dot(v1 - c, c - v2)
            if term <= 0:
                raise ValueError("–ü–æ–¥–∫–æ—Ä–µ–Ω–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ. –ü—Ä–æ–≤–µ—Ä—å —Ç–æ—á–∫–∏ —Å—Ö–æ–¥–∞.")
            f = np.sqrt(term)
            return f
        elif self.vpX is not None and self.vpY is not None:
            v1 = np.append(self.vpX, 1.0)
            v2 = np.append(self.vpY, 1.0)
            term = np.dot(v1 - c, c - v2)
            if term <= 0:
                raise ValueError("–ü–æ–¥–∫–æ—Ä–µ–Ω–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ. –ü—Ä–æ–≤–µ—Ä—å —Ç–æ—á–∫–∏ —Å—Ö–æ–¥–∞.")
            f = np.sqrt(term)
            return f
    def calc_R(self, f):
        self.camera.intrinsics.set_focal_length(f)
        K_inv = np.linalg.inv(self.camera.intrinsics.get())
        dx = K_inv @ np.append(self.vpX, 1.0)
        dy = K_inv @ np.append(self.vpY, 1.0) if self.vpY is not None else None
        dz = K_inv @ np.append(self.vpZ, 1.0) if self.vpZ is not None else None
        return self._build_rotation(dx, dy, dz)
    def _build_rotation(self, dx, dy, dz):
        # –ù–æ—Ä–º–∏—Ä—É–µ–º
        x = dx / np.linalg.norm(dx)
        if dy is not None and dz is not None:
            y = dy / np.linalg.norm(dy)
            z = dz / np.linalg.norm(dz)
            # –û—Ä—Ç–æ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: –ø–µ—Ä–µ—Å—Ç—Ä–æ–∏–º Y –∏ Z —Ç–∞–∫, —á—Ç–æ–±—ã —Å–∏—Å—Ç–µ–º–∞ –±—ã–ª–∞ –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–∞
            z = z - np.dot(z, x) * x - np.dot(z, y) * y
            z /= np.linalg.norm(z)
            y = np.cross(z, x)
            y /= np.linalg.norm(y)
        elif dy is None:
            z = dz / np.linalg.norm(dz)
            # –ï—Å–ª–∏ Y –Ω–µ –±—ã–ª –∑–∞–¥–∞–Ω ‚Äî –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º –µ–≥–æ
            y = np.cross(z, x)
            y /= np.linalg.norm(y)
        elif dz is None:
            y = dy / np.linalg.norm(dy)
            # –ï—Å–ª–∏ Z –Ω–µ –±—ã–ª –∑–∞–¥–∞–Ω ‚Äî –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º –µ–≥–æ
            z = np.cross(x, y)
            z /= np.linalg.norm(z)
        else:
            raise ValueError("–í —Å—Ü–µ–Ω–µ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∞ —Ç–æ—á–∫–∞ —Å—Ö–æ–¥–∞. –ü—Ä–æ–≤–µ—Ä—å —Ç–æ—á–∫–∏ —Å—Ö–æ–¥–∞.")
        # –°–æ–±–∏—Ä–∞–µ–º R: —Å—Ç–æ–ª–±—Ü—ã ‚Äî –æ—Å–∏ X, Y, Z –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö –∫–∞–º–µ—Ä—ã
        R = np.column_stack((x, y, z))
        z = R[:, 2]
        if z[2] > 0:  # –Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–∞–º–µ—Ä–∞ "—Å–º–æ—Ç—Ä–∏—Ç –≤–≤–µ—Ä—Ö" ‚Äî —ç—Ç–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ
            print("[VP Init] ‚ö†Ô∏è –ö–∞–º–µ—Ä–∞ —Å–º–æ—Ç—Ä–∏—Ç –Ω–∞–∑–∞–¥ ‚Äî –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é")
            R[:, 2] *= -1
            R[:, 1] = np.cross(R[:, 2], R[:, 0])
            R[:, 1] /= np.linalg.norm(R[:, 1])
        print(f' [VP Init] Determinant(R): {np.linalg.det(R)}')
        return R
    # def _build_rotation(self, dx, dy, dz):
    #     # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    #     x = dx / np.linalg.norm(dx)
    #     z = dz / np.linalg.norm(dz)
    #
    #     if dy is not None:
    #         y = dy / np.linalg.norm(dy)
    #
    #         # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º y, —á—Ç–æ–±—ã –æ–Ω–∞ –±—ã–ª–∞ –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–∞ x –∏ z
    #         # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º "–ø—Ä–∞–≤–∏–ª—å–Ω—É—é" y –∏–∑ x –∏ z
    #         y_proj = np.cross(z, x)
    #         y_proj /= np.linalg.norm(y_proj)
    #
    #         # –£—Ç–æ—á–Ω—è–µ–º x, —á—Ç–æ–±—ã –æ–Ω –±—ã–ª –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª–µ–Ω y_proj –∏ z
    #         x = np.cross(y_proj, z)
    #         x /= np.linalg.norm(x)
    #
    #         # –ü–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º y –µ—â—ë —Ä–∞–∑ ‚Äî —Ç–µ–ø–µ—Ä—å –æ–Ω–∞ —Ç–æ—á–Ω–æ –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–∞ x –∏ z
    #         y = np.cross(z, x)
    #         y /= np.linalg.norm(y)
    #     else:
    #         # –ï—Å–ª–∏ Y –Ω–µ –∑–∞–¥–∞–Ω, –¥–æ—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø—Ä–∞–≤—É—é —Ç—Ä–æ–π–∫—É
    #         y = np.cross(z, x)
    #         y /= np.linalg.norm(y)
    #
    #     # –°–æ–±–∏—Ä–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –ø–æ–≤–æ—Ä–æ—Ç–∞ R: [x_cam, y_cam, z_cam]
    #     R = np.column_stack((x, y, z))
    # –ü—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ R –ø—Ä–∞–≤–∞—è: det ‚âà +1
    # if np.linalg.det(R) < 0:
    #     # –ù–∞–ø—Ä–∏–º–µ—Ä, –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º y (–∏–ª–∏ x), —á—Ç–æ–±—ã –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é
    #     y = -y
    #     R = np.column_stack((x, y, z))
    #
    # return R
    def run(self, data=None, **kwargs):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–∞–º–µ—Ä—ã –ø–æ —Ç–æ—á–∫–∞–º —Å—Ö–æ–¥–∞.
        :return: –æ–±–Ω–æ–≤–ª—ë–Ω–Ω–∞—è –∫–∞–º–µ—Ä–∞
        """
        print("=" * 50)
        print("üéØ [VP Init] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —Ç–æ—á–∫–∞–º —Å—Ö–æ–¥–∞")
        print("=" * 50)
        f = self.calc_f()
        print(f"üî¨ –í—ã—á–∏—Å–ª–µ–Ω–æ —Ñ–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: f = {f:.4f}")
        R = self.calc_R(f)
        self.camera.extrinsics.set_rotation(R, from_type='vp')
        angles = self.camera.extrinsics.get_angles()
        print(f"üß≠ –£–≥–ª—ã –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏ (ZXY, –≥—Ä–∞–¥): {np.round(angles, 2)}")
        print("‚úÖ [VP Init] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        if self.debug_save_path is not None:
            from calibration.debug import visualize_vps_debug
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –≤: {self.debug_save_path}")
            visualize_vps_debug(self.camera, save_path=self.debug_save_path)
        print("=" * 50)
        return self.camera
# ==== source/distortion/__init__.py ====
# ==== source/distortion/extended_hough_transform.py ====
# ==== source/distortion/manual_line_distortion_correction.py ====
import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize
from core import Camera
def undistort_image(image, K, dist_coeffs):
    h, w = image.shape[:2]
    new_K, _ = cv2.getOptimalNewCameraMatrix(K, dist_coeffs, (w, h), alpha=1.0)
    return cv2.undistort(image, K, dist_coeffs, None, K)
def undistort_point(point, K, dist_coeffs):
    point = np.array(point, dtype=np.float32).reshape(-1, 1, 2)  # –ü–µ—Ä–µ–¥–∞–µ–º —Ç–æ—á–∫—É –∫–∞–∫ –º–∞—Å—Å–∏–≤
    undistorted_point = cv2.undistortPoints(point, K, dist_coeffs)
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –ø–∏–∫—Å–µ–ª—å–Ω—ã–µ
    undistorted_point_pixels = cv2.convertPointsToHomogeneous(undistorted_point)
    undistorted_point_pixels = np.dot(undistorted_point_pixels, K.T)
    pixel_coords = undistorted_point_pixels[0, 0]
    return pixel_coords[:2]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–∏–∫—Å–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
def curve_residuals(curves_undistorted):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –æ—à–∏–±–∫—É –ø—Ä—è–º–æ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∫—Ä–∏–≤–æ–π (—Å—É–º–º–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–æ –Ω–∞–∏–ª—É—á—à–µ–π –ø—Ä—è–º–æ–π).
    """
    total_error = 0
    for curve in curves_undistorted:
        if len(curve) < 2:
            continue
        curve = np.array(curve)
        # –ü–æ–¥–≥–æ–Ω—è–µ–º –ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é 1-–π —Å—Ç–µ–ø–µ–Ω–∏
        fit = np.polyfit(curve[:, 0], curve[:, 1], 1)
        y_fit = np.polyval(fit, curve[:, 0])
        error = np.mean((curve[:, 1] - y_fit) ** 2)
        total_error += error
    return total_error
def objective(k, curves):
    """
    k ‚Äî —ç—Ç–æ –º–∞—Å—Å–∏–≤ [k1], –ø–∞—Ä–∞–º–µ—Ç—Ä —Ä–∞–¥–∏–∞–ª—å–Ω–æ–π –¥–∏—Å—Ç–æ—Ä—Å–∏–∏
    """
    dist_coeffs = np.array([k[1], k[2], 0, 0, 0], dtype=np.float32)  # —Ç–æ–ª—å–∫–æ k1
    K = np.array([
        [k[0], 0, 960],
        [0, k[0], 540],
        [0, 0, 1]
    ], dtype=np.float32)
    undistorted_curves = []
    for curve in curves:
        undist = []
        for pt in curve:
            new_pt = undistort_point(pt, K, dist_coeffs)
            undist.append(new_pt)
        undistorted_curves.append(undist)
    return curve_residuals(undistorted_curves)
from scipy.optimize import minimize
# –ó–∞–≥—Ä—É–∑–∫–∞
curves = np.load("clicked_curves.npy", allow_pickle=True)
# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
result = minimize(
    fun=objective,
    x0=np.array([1200, 0.0, 0.0]),  # –Ω–∞—á–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ k1
    args=(curves,),
    method="Powell",  # —Ä–∞–±–æ—Ç–∞–µ—Ç –ª—É—á—à–µ –±–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
    bounds=[(800, 2000), (-1.0, 1.0), (-1.0, 1.0)]
)
f_opt, k1_opt, k2_opt = result.x
print(f"üì∑ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ñ–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ f = {f_opt:.2f}")
print(f"üîß –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ k1 = {k1_opt:.6f}")
print(f"üîß –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ k2 = {k2_opt:.6f}")
camera = Camera("../../example/pushkin_aksakov/image/crossroads.jpg")
camera.intrinsics.set_focal_length(f_opt)
K = camera.intrinsics.get()
image = undistort_image(camera.get_image(), K, np.array([k1_opt, k2_opt, 0, 0, 0], dtype=np.float32))
import matplotlib.pyplot as plt
# –ü–æ–ª—É—á–∞–µ–º –≤—ã–ø—Ä—è–º–ª–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
# image = undistort_image(
#     camera.get_image(),
#     K,
#     np.array([k1_opt, k2_opt, 0, 0, 0], dtype=np.float32)
# )
#
# image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
# cv2.imwrite("../../example/pushkin_aksakov/image/undistort_opencv.png", image_bgr)# ==== source/distortion/cpp/bindings.cpp ====
#include <pybind11/pybind11.h>
#include "hough.hpp"
namespace py = pybind11;
PYBIND11_MODULE(mymodule, m) {
    py::class_<MyMath>(m, "MyMath")
        .def(py::init<>())
        .def("add", &MyMath::add)
        .def("mul", &MyMath::mul);
}
# ==== source/distortion/cpp/hough.cpp ====
#include <pybind11/pybind11.h>
#include <pybind11/numpy.h>
#include <cmath>
#ifndef M_PI
#define M_PI 3.14159265358979323846
#endif
namespace py = pybind11;
py::array_t<float> hough_transform_with_orientation(
    py::array_t<uint8_t> edges,
    py::array_t<float> orientations,
    float angle_resolution_deg,
    float rho_resolution)
{
    auto buf_edges = edges.unchecked<2>();
    auto buf_orient = orientations.unchecked<2>();
    int height = buf_edges.shape(0);
    int width = buf_edges.shape(1);
    int diag_len = static_cast<int>(std::hypot(width, height));
    int num_thetas = static_cast<int>(180.0 / angle_resolution_deg);
    int num_rhos = 2 * diag_len;
    py::array_t<float> accumulator({num_rhos, num_thetas});
    auto acc = accumulator.mutable_unchecked<2>();
    double deg2rad = M_PI / 180.0;
    for (int y = 0; y < height; y++) {
        for (int x = 0; x < width; x++) {
            int window = 3;  // —Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ –≤–æ–∫—Ä—É–≥ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏
            if (buf_edges(y, x)) {
                float ori_rad = buf_orient(y, x);
                float ori_deg = ori_rad * 180.0f / M_PI;
                int t_center = static_cast<int>(ori_deg / angle_resolution_deg);
                for (int dt = -window; dt <= window; dt++) {
                    int t = t_center + dt;
                    if (t < 0 || t >= num_thetas) continue;
                    double angle = t * angle_resolution_deg * deg2rad;
                    double rho = x * std::cos(angle) + y * std::sin(angle);
                    int r_idx = static_cast<int>((rho + diag_len) / rho_resolution);
                    if (r_idx >= 0 && r_idx < num_rhos)
                        acc(r_idx, t) += 1.0f;
                }
            }
        }
    }
    return accumulator;
}
PYBIND11_MODULE(mymodule, m) {
    m.def("hough_transform_with_orientation", &hough_transform_with_orientation,
          py::arg("edges"),
          py::arg("orientations"),
          py::arg("angle_resolution_deg") = 1.0f,
          py::arg("rho_resolution") = 1.0f,
          "Hough transform using edge image and orientation map");
}# ==== source/vp_detection/__init__.py ====
from .vanishing_point_estimator import VanishingPointEstimatorManual
__all__ = [
    "VanishingPointEstimatorManual",
]
# ==== source/vp_detection/base.py ====
from abc import ABC, abstractmethod
class Detector(ABC):
    def run(self, **kwargs):
        pass
# ==== source/vp_detection/vanishing_point_estimator.py ====
import numpy as np
from .base import Detector
class VanishingPointEstimatorManual(Detector):
    def __init__(self):
        pass
    @staticmethod
    def _normal_vector(x1, y1, x2, y2):
        dx = x2 - x1
        dy = y2 - y1
        normal = np.array([-dy, dx]) / np.hypot(dx, dy)
        return normal
    def estimate(self, lines):
        A = []
        b = []
        for (x1, y1), (x2, y2) in lines:
            n = self._normal_vector(x1, y1, x2, y2)
            A.append(n)
            b.append(np.dot(n, [x1, y1]))
        A = np.array(A)
        b = np.array(b)
        vp = np.linalg.lstsq(A, b, rcond=None)[0]
        return vp
# ==== example/pushkin_aksakov/example.py ====
from source import CalibrationPipeline, Camera, VanishingPointCalibration, \
    RefineOptimizer
from source.utils import load_lines, load_lines_from_json
from calibration.refine import residual_interline_distance, residual_parallel_group, \
    residual_reprojection_line
from calibration.debug import load_scene_gps, visualize_source
import numpy as np
camera = Camera('image/pattern_corrected_image.png')
vp1 = [3974.185, -248.69977]
vp2 = [768.4042, 2362.912]
vp3 = [-24.940735, -669.0249]
vps_auto = np.array([vp1, vp3, vp2])
# –ù–∞–±–æ—Ä –Ω–∞–π–¥–µ–Ω–Ω—ã–π —á–µ—Ä–µ–∑ RANSAK
# vp1_new = [3.535e+03, -1.270e+02]
# vp2_new = [164.36434109, -476.74418605]
# vps_auto_new = np.array([vp1_new, vp2_new])
vp_init = VanishingPointCalibration(camera, debug_save_path='image/vp.png')
vp_init.set_vanishing_points(*vps_auto)
def back_refine():
    global camera
    data = {
        "dist_between_line_1": load_lines('marked/dist_between_line_1.json'),
        "dist_between_line_2": load_lines('marked/dist_between_line_2.json'),
        "lane_lines": load_lines('marked/parallel_line_1.json'),
        "vertical_lines": load_lines('marked/vertical_lines.json'),
    }
    resualds_blocks = [
        lambda cam, data: residual_interline_distance(cam, data, group="dist_between_line_1", expected=9),
        lambda cam, data: residual_interline_distance(cam, data, group="dist_between_line_2", expected=7),
        lambda cam, data: residual_parallel_group(cam, data, group="lane_lines"),
    ]
    refiner_first = RefineOptimizer(camera=camera,
                                    residual_blocks=resualds_blocks,
                                    mask=[0, 6],
                                    bounds=([900, 5], [2000, 30]),
                                    debug_save_path='image/',
                                    gps_origin=(54.723767, 55.933369),
                                    )
    pipeline = CalibrationPipeline([vp_init, refiner_first])
    camera = pipeline.run(camera, data)
back_refine()  # –î–æ–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ –æ–±—Ä–∞—Ç–Ω—É—é –ø—Ä–æ–µ–∫—Ü–∏—é
def direct_refine():
    global camera
    data = {"lines_gps_and_pixel": load_lines_from_json('marked/lines_gps_to_pixel.json')
            }
    resualds_blocks = [
        lambda cam, data: residual_reprojection_line(cam, data, group="lines_gps_and_pixel",
                                                     gps_origin=(54.723767, 55.933369)),
    ]
    refiner_first = RefineOptimizer(camera=camera,
                                    residual_blocks=resualds_blocks,
                                    debug_save_path='image/',
                                    )
    pipeline = CalibrationPipeline([vp_init, refiner_first])
    camera = pipeline.run(camera, data)
#direct_refine()  # –î–æ–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ –ø—Ä—è–º—É—é –ø—Ä–æ–µ–∫—Ü–∏—é
def gibrid():
    global camera
    data = {
        "dist_between_line_1": load_lines('marked/dist_between_line_1.json'),
        "dist_between_line_2": load_lines('marked/dist_between_line_2.json'),
        "lane_lines": load_lines('marked/parallel_line_1.json'),
        "lines_gps_and_pixel": load_lines_from_json('marked/lines_gps_to_pixel.json')
    }
    resualds_blocks_first = [
        lambda cam, data: residual_interline_distance(cam, data, group="dist_between_line_1", expected=8),
        lambda cam, data: residual_interline_distance(cam, data, group="dist_between_line_2", expected=5.5),
        lambda cam, data: residual_parallel_group(cam, data, group="lane_lines"),
    ]
    refiner_first = RefineOptimizer(camera=camera,
                                    residual_blocks=resualds_blocks_first,
                                    mask=[0, 6],
                                    bounds=([900, 5], [2000, 30]),
                                    debug_save_path='image/')
    resualds_blocks_second = [
        lambda cam, data: residual_reprojection_line(cam, data, group="lines_gps_and_pixel",
                                                     gps_origin=(54.723767, 55.933369)),
    ]
    refiner_second = RefineOptimizer(camera=camera, residual_blocks=resualds_blocks_second, debug_save_path='image/')
    pipeline = CalibrationPipeline([vp_init, refiner_first, refiner_second])
    camera = pipeline.run(camera, data)
# gibrid()
# –†–∞–∑–º–µ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
# from utils.data_markup_tool import LineAnnotationTool
#
# line_tool = LineAnnotationTool("image/pattern_corrected_image.png","marked","vertical_lines.json")
# line_tool.run()
# –¢–µ—Å—Ç—ã
# from source.calibration.debug import visualize_grid_debug
# from source.core import PointND
# from utils.gps_connection_world import gps_to_enu, enu_to_gps
#
# gps_origin = (54.723767, 55.933369)
# camera.set_params_from_list([1263.28, -142.97, 51.84, 172.31, 0.0, 0.0, 28.88])
# visualize_grid_debug(camera, PointND(camera.intrinsics.get_main_point()))
#
# point = - camera.project_back(PointND([775.49946776, 886.09295195])).get()
# print(point)
# # point = [ -9.72, -15.13]
# enu = enu_to_gps(*point[:2], gps_origin[0], gps_origin[1])
# print(enu)
# ==== example/pushkin_aksakov/example_dist.py ====
import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize
points = []
# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –º—ã—à–∏ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞ –∫—Ä–∏–≤—ã—Ö
def mouse_callback(event, x, y, flags, param):
    if event == cv2.EVENT_LBUTTONDOWN:
        points.append((x, y))
def distort_point(p, k, cx, cy):
    x, y = p[0] - cx, p[1] - cy
    r2 = x**2 + y**2
    scale = 1 + k * r2
    return x * scale + cx, y * scale + cy
def undistort(points, k, cx, cy):
    return np.array([distort_point(p, -k, cx, cy) for p in points])
# –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å: –Ω–∞—Å–∫–æ–ª—å–∫–æ "–Ω–µ–ø—Ä—è–º–∞—è" –ª–∏–Ω–∏—è
def loss_fn(k, original_pts, cx, cy):
    undistorted = undistort(original_pts, k, cx, cy)
    x, y = undistorted[:, 0], undistorted[:, 1]
    A = np.vstack([x, np.ones_like(x)]).T
    m, c = np.linalg.lstsq(A, y, rcond=None)[0]
    y_fit = m * x + c
    return np.mean((y - y_fit) ** 2)
# –ó–∞–≥—Ä—É–∑–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
img = cv2.imread("image/crossroads.jpg")
if img is None:
    raise FileNotFoundError("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
h, w = img.shape[:2]
cx, cy = w / 2, h / 2
cv2.imshow("–í—ã–¥–µ–ª–∏ –ª–∏–Ω–∏—é (ESC —á—Ç–æ–±—ã –∑–∞–≤–µ—Ä—à–∏—Ç—å)", img)
cv2.setMouseCallback("–í—ã–¥–µ–ª–∏ –ª–∏–Ω–∏—é (ESC —á—Ç–æ–±—ã –∑–∞–≤–µ—Ä—à–∏—Ç—å)", mouse_callback)
while True:
    key = cv2.waitKey(1)
    if key == 27 or len(points) > 10:  # ESC –∏–ª–∏ –±–æ–ª—å—à–µ 10 —Ç–æ—á–µ–∫
        break
cv2.destroyAllWindows()
points = np.array(points)
# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –∏—Å–∫–∞–∂–µ–Ω–∏—è
res = minimize(loss_fn, x0=[0.0], args=(points, cx, cy), method='Nelder-Mead')
k_opt = res.x[0]
print(f"–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä –∏—Å–∫–∞–∂–µ–Ω–∏—è: k = {k_opt:.6f}")
# –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ç–∫–∏ –∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
map_x, map_y = np.meshgrid(np.arange(w), np.arange(h))
map_undistort = np.zeros((h, w, 2), dtype=np.float32)
for y in range(h):
    for x in range(w):
        dx, dy = x - cx, y - cy
        r2 = dx**2 + dy**2
        scale = 1 + k_opt * r2
        x_u = dx / scale + cx
        y_u = dy / scale + cy
        map_undistort[y, x] = [x_u, y_u]
undistorted = cv2.remap(img, map_undistort[..., 0], map_undistort[..., 1], cv2.INTER_LINEAR)
# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title("–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.scatter(*zip(*points), c='red')
plt.subplot(1, 2, 2)
plt.title("–ü–æ—Å–ª–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–∏—Å—Ç–æ—Ä—Å–∏–∏")
plt.imshow(cv2.cvtColor(undistorted, cv2.COLOR_BGR2RGB))
plt.tight_layout()
plt.show()
# ==== example/pushkin_aksakov/old/example_back.py ====
from core.camera_model import Camera
from calibration.utils.data_preparation import load_data, prep_data_parallel
from calibration.refine.back.back_optimization import BackProjectionOptimizer
import numpy as np
# matplotlib.use("TkAgg")
camera = Camera('../image/pattern_corrected_image.png')
# –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –ª–∏–Ω–∏–π
# plot = Plot(camera)
# plot.draw_line(load_data('marked_data_4/parallel_lines_1.txt'))
# plot.draw_line(load_data('marked_data_4/parallel_lines_2.txt'))
# plot.draw_line(load_data('marked_data_4/parallel_lines_3.txt'))
# # plot.draw_line(load_data('marked_data_4/parallel_lines_4.txt'))
# plot.draw_line(load_data('marked_data_4/point_to_point.txt'))
# plot.visible()
data = {
    # 'angle': prep_data_angle(load_data(('marked_data_3/angle_lines.txt'))),
    'parallel-1': prep_data_parallel(load_data('../marked_data_4/parallel_lines_1.txt')),
    'point_to_point': np.array(load_data('../marked_data_4/point_to_point.txt')),
    'parallel-2': prep_data_parallel(load_data('../marked_data_4/parallel_lines_2.txt')),
    'parallel-3': prep_data_parallel(load_data('../marked_data_4/parallel_lines_3.txt')),
    # 'parallel-4': prep_data_parallel(load_data('marked_data_4/parallel_lines_4.txt')),
    # 'parallel-4': prep_data_parallel(load_data('marked_data/parallel_lines_1.txt')),
    # 'parallel-5': prep_data_parallel(load_data('marked_data/parallel_lines_2.txt')),
    # 'point_to_point_2': np.array(load_data('marked_data/point_to_point.txt'))
}
# # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
#
camera.calc_R([-158.07642684,   49.78161572,  173.91438536])
optimize = BackProjectionOptimizer(camera)
optimize.back_projection(data)
# #
# # # # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
# HIST = [np.sum(values) for values in RESIDUALS]
#
# plt.figure(1)
# plt.subplot(1, 2, 1)
# plt.title('–ì—Ä–∞—Ñ–∏–∫ –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç–∏')
# plt.ylabel('–¢–æ—á–Ω–æ—Å—Ç—å')
# plt.xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π')
# plt.plot(np.arange(0, len(HIST)), HIST)
#
# plt.subplot(1, 2, 2)
# plt.plot(RESIDUALS[0], label='–ü–µ—Ä–≤–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è')
# plt.plot(RESIDUALS[-1], label='–ü–æ—Å–ª–µ–¥–Ω—è—è –∏—Ç–µ—Ä–∞—Ü–∏—è')
# plt.axvspan(0, 3, color='lightgrey', alpha=0.5,label='–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –ø—Ä—è–º—ã–µ')
# # plt.axvspan(1, 3, color='lightgrey', alpha=0.5)
# plt.axvspan(3, 14, color='darkgrey', alpha=0.5,label='–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç —Ç–æ—á–∫–∏ –¥–æ —Ç–æ—á–∫–∏')
# # plt.axvline(x=1, color='black', linestyle='--')  # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è –Ω–∞ X=5
# # plt.axvline(x=3, color='black', linestyle='--')
# plt.text(2.5, 12, '–û–±–ª–∞—Å—Ç—å 1', horizontalalignment='center', verticalalignment='center', color='black', fontsize=10)
# plt.text(7.5, 12, '–û–±–ª–∞—Å—Ç—å 2', horizontalalignment='center', verticalalignment='center', color='black', fontsize=10)
# plt.title('–ü–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –¥–ª—è –≤—Å–µ—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö')
# plt.ylabel('–ü–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å')
# plt.xlabel('–ù–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö')
# plt.legend()
# plt.show()
# PARAMS = np.array(PARAMS)
# #
# plt.plot(PARAMS[:, 0], label='f')
# plt.plot(PARAMS[:, 1], label='Z')
# plt.plot(PARAMS[:, 2], label='X')
# plt.plot(PARAMS[:, 3], label='Y')
# plt.plot(PARAMS[:, 4], label='H')
# plt.legend()
# plt.show()
# –¢–µ—Å—Ç—ã
# camera.set_params(load_params('marked_data/calib_data.txt'))
# optimize = NewOptimization(camera)
#
# data_calc = prep_data_back_to_reverse(camera,
#                                       load_data('marked_data/point_to_point.txt') + load_data(
#                                           'marked_data/parallel_lines_1.txt') + load_data(
#                                           'marked_data/parallel_lines_2.txt'))
# plot = Plot(camera)
# plot.draw_line(data_calc, thickness=7)
# plot.draw_line(load_data('marked_data/parallel_lines_1.txt'), color=(0, 255, 0))
# plot.draw_line(load_data('marked_data/parallel_lines_2.txt'), color=(0, 255, 0))
# plot.draw_line(load_data('marked_data/point_to_point.txt'), color=(0, 255, 0))
# plot.visible(DisplayMode.INTERACTIVE)
# data = load_data('calibration_lines.txt')
# print(np.linalg.norm(optimize._back_project_line_3d(*data[0], load_params('calib_data.txt'))))
# –ü—Ä—è–º–∞—è –ª–∏–Ω–∏—è
# camera = Camera()
# camera.load_scene('image/image.webp')
# print(load_params('marked_data/calib_data.txt'))
# camera.set_params(load_params('marked_data/calib_data.txt'))
#
# plot_coord = []
# for start, end in load_data('marked_data/parallel_lines_1.txt'):
#     start3d = camera.back_crop(start)
#     end3d = camera.back_crop(end)
#     plot_coord.append([start3d, end3d])
#
# for i in range(1, len(plot_coord)):
#     start1, end1 = plot_coord[i - 1]
#     start2, end2 = plot_coord[i]
#     plt.plot([start1.get()[0], end1.get()[0]], [start1.get()[1], end1.get()[1]],
#              label=f'–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ\n–ù–∞—á–∞–ª–æ: {np.linalg.norm(start2.get() - start1.get())}\n–ö–æ–Ω–µ—Ü:  {np.linalg.norm(end2.get() - end1.get())}')
#     plt.scatter(start1.get()[0], start1.get()[1])
# start2, end2 = plot_coord[-1]
# plt.plot([start2.get()[0], end2.get()[0]], [start2.get()[1], end2.get()[1]])
# –ü—Ä—è–º–∞—è –ª–∏–Ω–∏—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
# for i, (start, end) in enumerate(load_data('marked_data/parallel_lines_2.txt')):
#     start3d = camera.back_crop(start)
#     end3d = camera.back_crop(end)
#     x = np.linspace(-100, 100, 100)
#     y = fun_lines(x, start3d, end3d)
#     points = [camera.direct_crop(PointND([xi, yi])) for xi, yi in zip(x, y)]
#     x_new, y_new = zip(*[p.get() for p in points])
#     plt.scatter([start.get()[0], end.get()[0]], [start.get()[1], end.get()[1]])
#     plt.plot(x_new, y_new, label=f'Transformed Line 1 - {i}')
# coord1.append(np.array([x, y]))
# ==== example/pushkin_aksakov/old/example_direct.py ====
from core.camera_model import Camera
import numpy as np
# Line_Y = [[[297, 521], [1365, 272]], [[378, 555], [1462, 301]], [[417, 702], [1398, 430]], [[843, 894], [1343, 720]],
#           [[1197, 283], [1396, 244]]]
# Line_X = [[[755, 810], [601, 453]], [[1258, 962], [745, 315]], [[1388, 653], [1096, 345]], [[949, 268], [852, 179]]]
#
# camera = calc_init_camera('../../data/crossroads_pushkin_aksakov/crossroads_not_dist.jpg', [Line_X, Line_Y])
#
# # –û–ø–æ—Ä–Ω–∞—è —Ç–æ—á–∫–∞ (—Ü–µ–Ω—Ç—Ä –ª–æ–∫–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã)
# ref_lat, ref_lon = 54.723767, 55.933369
#
# LINE_CALIB = [
#     [[54.723767, 55.933369, 779, 874], [54.723936, 55.933454, 600, 452]],
#     [[54.723767, 55.933369, 779, 874], [54.723714, 55.933668, 1399, 694]],
#     [[54.723714, 55.933668, 1399, 694], [54.723884, 55.933750, 1084, 344]],
#     [[54.723884, 55.933750, 1084, 344], [54.723936, 55.933454, 600, 452]],
#     [[54.723854, 55.933420, 679, 625], [54.723804, 55.933712, 1222, 481]],
#     [[54.723735, 55.933514, 1133, 790], [54.723917, 55.933596, 815, 394]],
#     [[54.723863, 55.933352, 535, 668], [54.723793, 55.933774, 1320, 451]],
#     [[54.723696, 55.933495, 1219, 911], [54.723957, 55.933613, 768, 340]],
#     # [[54.723889, 55.933191, 95, 803], [54.723761, 55.933949, 1565, 392]],
#     # [[54.723764, 55.933953, 1558, 386], [54.723847, 55.933996, 1395, 268]],
# ]
# #
# LINE_CALIB_NEW = []
# # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ø–µ—Ä–≤–æ–π –ª–∏–Ω–∏–∏ –≤ ENU
# for line in LINE_CALIB:
#     (lat1, lon1, x1, y1), (lat2, lon2, x2, y2) = line
#     e1, n1 = gps_to_enu(lat1, lon1, ref_lat, ref_lon)
#     e2, n2 = gps_to_enu(lat2, lon2, ref_lat, ref_lon)
#
#     LINE_CALIB_NEW.append([[x1, y1, float(e1), float(n1), 0], [x2, y2, float(e2), float(n2), 0]])
# #
# LINE_PREP = []
# for line in LINE_CALIB_NEW:
#     start, end = line
#     start2D, start3D = PointND(start[0:2]), PointND(start[2:6])
#     end2D, end3D = PointND(end[0:2]), PointND(end[2:6])
#
#     LINE_PREP.append([(start2D, start3D), (end2D, end3D)])
# #
# # print(LINE_CALIB_NEW)
# camera = Camera('image/pattern_corrected_image.png')
# camera.set_params([929.67, -141.65, 17.12, -186.47, 5.31, 3.68, 27.73])
# optimize = DirectProjectionOptimizer(camera)
# camera, info, cost_history, history = optimize.optimize_reprojection(LINE_PREP)
# print("–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞:", info.cost)
# print("–§–∏–Ω–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:", np.around(info.x, 2))
#
# plot = Plot(camera)
# plot.draw_tranform_line(LINE_PREP, save=True)
# plot.draw_calibration_line(LINE_PREP, save=True)
#
# #
# import matplotlib.pyplot as plt
#
# plt.plot(np.arange(0, len(cost_history)), np.log(cost_history))
# plt.ylabel('–¢–æ—á–Ω–æ—Å—Ç—å')
# plt.xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π')
# plt.show()
import matplotlib.pyplot as plt
import cv2
def draw_coordinate_axes_from_vps(vanishing_points, center, scale=100, labels=None, colors=None, flip_z=True):
    """
    –†–∏—Å—É–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–Ω—ã–µ –æ—Å–∏ X, Y, Z –æ—Ç —Ü–µ–Ω—Ç—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é –∫ —Ç–æ—á–∫–∞–º —Å—Ö–æ–¥–∞.
    :param vanishing_points: —Å–ø–∏—Å–æ–∫ [(x1, y1), (x2, y2), (x3, y3)] ‚Äî –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã VP
    :param center: (cx, cy) ‚Äî —Ü–µ–Ω—Ç—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∏–ª–∏ —Ü–µ–Ω—Ç—Ä –ø—Ä–æ–µ–∫—Ü–∏–∏ –∫–∞–º–µ—Ä—ã)
    :param scale: –¥–ª–∏–Ω–∞ —Å—Ç—Ä–µ–ª–æ–∫ (–≤ –ø–∏–∫—Å–µ–ª—è—Ö)
    :param labels: –ø–æ–¥–ø–∏—Å–∏ –æ—Å–µ–π, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ['X', 'Y', 'Z']
    :param colors: —Ü–≤–µ—Ç–∞ –æ—Å–µ–π, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ['red', 'green', 'blue']
    """
    if labels is None:
        labels = ['X', 'Y', 'Z']
    if colors is None:
        colors = ['red', 'green', 'blue']
    cx, cy = center
    for i, (x, y) in enumerate(vanishing_points):
        dx = x - cx
        dy = y - cy
        norm = np.hypot(dx, dy)
        dx_scaled = dx / norm * scale
        dy_scaled = dy / norm * scale
        if flip_z and labels[i].upper() == 'Z':
            dx_scaled *= -1
            dy_scaled *= -1
        # –†–∏—Å—É–µ–º —Å—Ç—Ä–µ–ª–∫—É –æ—Å–∏
        plt.arrow(cx, cy, dx_scaled, dy_scaled,
                  color=colors[i], width=1.2, head_width=10, length_includes_head=True)
image = cv2.imread('../image/pattern_corrected_image.png')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
image_width = 1920
image_height = 1080
cx, cy = image_width // 2, image_height // 2
camera = Camera('../image/pattern_corrected_image.png')
camera.set_params([1419.59, -142.56, 49.5, -185.62, -12.82, -18.38, 30.63])
K = camera.get_K()
print(f'Matrix intrinsics:\n{K}')
R = camera.get_R()
print(f'Matrix rot:\n{R}')
C = np.array([[-12.82], [-18.38], [30.63]])  # —Å—Ç–æ–ª–±–µ—Ü, —á—Ç–æ–±—ã —Å–æ–±—Ä–∞—Ç—å [R | t]
t = -R @ C  # –≤–µ–∫—Ç–æ—Ä –ø–µ—Ä–µ–Ω–æ—Å–∞ (–ø–µ—Ä–µ–≤–æ–¥ —Ü–µ–Ω—Ç—Ä–∞ –∫–∞–º–µ—Ä—ã –≤ —Å–∏—Å—Ç–µ–º—É –∫–∞–º–µ—Ä—ã)
Rt = np.hstack((R, t))  # 3x4 –º–∞—Ç—Ä–∏—Ü–∞ [R | t]
P = K @ Rt
VP1 = K @ R[:, 0]
VP1_pixel = [VP1[0] / VP1[2], VP1[1] / VP1[2]]
VP2 = K @ R[:, 1]
VP2_pixel = [VP2[0] / VP2[2], VP2[1] / VP2[2]]
V3_calc = np.dot(VP1, VP2)
VP3 = K @ R[:, 2]
VP3_pixel = [VP3[0] / VP3[2], VP3[1] / VP3[2]]
VP_opt = [VP1_pixel, VP2_pixel, VP3_pixel]
VP = [[3974.185, -248.69977], [-24.940735, -669.0249], [768.4042, 2362.912]]
center = (image_width // 2, image_height // 2)
plt.imshow(image_rgb)
plt.xlim(0, image_width)
plt.ylim(image_height, 0)
draw_coordinate_axes_from_vps(VP_opt, center, scale=150)
# draw_coordinate_axes_from_vps(VP_opt, center, scale=150)
plt.title("–ú–∏—Ä–æ–≤—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–Ω—ã–µ –æ—Å–∏ —á–µ—Ä–µ–∑ —Ç–æ—á–∫–∏ —Å—Ö–æ–¥–∞")
plt.show()
# def pixel_to_world(px, K, R, C, plane_normal=np.array([0, 0, 1]), plane_point=np.array([0, 0, 0])):
#     """
#     –ü—Ä–æ–µ—Ü–∏—Ä—É–µ—Ç –ø–∏–∫—Å–µ–ª—å px = [u,v] –Ω–∞ –ø–ª–æ—Å–∫–æ—Å—Ç—å, –∑–∞–¥–∞–≤–∞–µ–º—É—é normal –∏ —Ç–æ—á–∫–æ–π –Ω–∞ –ø–ª–æ—Å–∫–æ—Å—Ç–∏.
#     """
#     u, v = px
#     K_inv = np.linalg.inv(K)
#
#     # –õ—É—á –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö –∫–∞–º–µ—Ä—ã
#     d_c = K_inv @ np.array([u, v, 1])
#
#     # –ü–µ—Ä–µ–≤–æ–¥ –≤ –º–∏—Ä–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É
#     d_w = R.T @ d_c
#     d_w = d_w / np.linalg.norm(d_w)  # –∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å
#
#     # –¶–µ–Ω—Ç—Ä –∫–∞–º–µ—Ä—ã
#     C = C.reshape((3, ))
#
#     # –†–µ—à–∞–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –ø—Ä—è–º–æ–π —Å –ø–ª–æ—Å–∫–æ—Å—Ç—å—é
#     numerator = np.dot(plane_normal, (plane_point - C))
#     denominator = np.dot(plane_normal, d_w)
#     lam = numerator / denominator
#
#     point_world = C + lam * d_w
#     return point_world
#
#
# px = [1000, 500]  # –ø–∏–∫—Å–µ–ª—å
# C_world = np.array([-12.82, -18.38, 30.63])
# pt_world = pixel_to_world(px, K, R, C_world)
#
# print("3D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã:", pt_world)
# # –ü–æ–∫–∞–∑–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
#
# origin = np.array([0, 0, 0, 1])  # –≥–æ–º–æ–≥–µ–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
# length = 10  # –¥–ª–∏–Ω–∞ –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ 3D (–≤ —É—Å–ª–æ–≤–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü–∞—Ö)
#
# # 3D-–∫–æ–Ω—Ü—ã –≤–µ–∫—Ç–æ—Ä–æ–≤ –æ—Å–µ–π
# x_axis_end = np.array([length, 0, 0])
# y_axis_end = np.array([0, length, 0])
# z_axis_end = np.array([0, 0, length])
#
#
# def project_point(p3d):
#     p = P @ np.append(p3d, 1)
#     return p[:2] / p[2]
#
#
# # –¶–µ–Ω—Ç—Ä –∫–∞–º–µ—Ä—ã –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
# center_pixel = project_point([0, 0, 0])
# x_pixel = project_point(x_axis_end)
# y_pixel = project_point(y_axis_end)
# z_pixel = project_point(z_axis_end)
#
# # –†–∏—Å—É–µ–º –æ—Å–∏
# plt.arrow(center_pixel[0], center_pixel[1], x_pixel[0] - center_pixel[0], x_pixel[1] - center_pixel[1],
#           color='red', width=5, label='X')
# plt.arrow(center_pixel[0], center_pixel[1], y_pixel[0] - center_pixel[0], y_pixel[1] - center_pixel[1],
#           color='green', width=5, label='Y')
# plt.arrow(center_pixel[0], center_pixel[1], z_pixel[0] - center_pixel[0], z_pixel[1] - center_pixel[1],
#           color='blue', width=5, label='Z')
# ==== example/karls_marks/example.py ====
import matplotlib.pyplot as plt
from source import CalibrationPipeline, Camera, VanishingPointCalibration, \
    RefineOptimizer, PointND
from source.calibration.utils import load_lines, load_lines_from_json, extract_direction_vectors_from_lines
from calibration.refine import residual_interline_distance, residual_parallel_group, \
    residual_reprojection_line
from calibration.debug import load_scene_gps, visualize_source
from vp_detection import VanishingPointEstimatorManual
import numpy as np
lines_vp1 = load_lines("marked/horizontal_lines.json")
lines_vp3 = load_lines("marked/vertical_lines.json")
vp1_manual = VanishingPointEstimatorManual().estimate(lines_vp1)
vp3_manual = VanishingPointEstimatorManual().estimate(lines_vp3)
vps_manual = np.array([vp1_manual, vp3_manual])
camera = Camera('image/pattern_corrected_image.png')
vp_init = VanishingPointCalibration(camera, debug_save_path='image/vp.png')
vp_init.set_vanishing_points(vpX=vps_manual[0], vpZ=vps_manual[1])
from utils import AnnotationParser
annotation_parser = AnnotationParser("marked/data_full.json")
data = {
    "pedestrian crossing": annotation_parser.get_lines_by_class("pedestrian crossing"),
    "pedestrian crossing 2": annotation_parser.get_lines_by_class("pedestrian crossing 2"),
    "pedestrian crossing 3": annotation_parser.get_lines_by_class("pedestrian crossing 3"),
    "distance between line": annotation_parser.get_lines_by_class("distance between line"),
}
resualds_blocks_first = [
    lambda cam, data: residual_interline_distance(cam, data, group="pedestrian crossing", expected=4),
    lambda cam, data: residual_interline_distance(cam, data, group="pedestrian crossing 2", expected=4),
    lambda cam, data: residual_interline_distance(cam, data, group="pedestrian crossing 3", expected=4),
    lambda cam, data: residual_interline_distance(cam, data, group="distance between line", expected=3.5),
]
refiner_first = RefineOptimizer(camera=camera,
                                residual_blocks=resualds_blocks_first,
                                mask=[0, 6],
                                bounds=([800, 5], [2000, 30]),
                                # debug_save_path='image/',
                                )
pipeline = CalibrationPipeline([vp_init, refiner_first])
camera = pipeline.run(camera, data)
# from scipy.spatial.transform import Rotation as R
# from scipy.optimize import minimize
# import numpy as np
#
#
# # === LOSS-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã ===
#
# def loss_vertical_alignment(omega, R0, K, lines_img):
#     delta_R = R.from_rotvec(omega).as_matrix()
#     R_corr = delta_R @ R0
#     z_world = np.array([0, 0, 1])
#
#     loss = 0.0
#     for line_dir in lines_img:
#         line_dir = line_dir / np.linalg.norm(line_dir)
#         v_cam = R_corr @ z_world
#         v_img = K @ v_cam
#         v_img = v_img[:2] / v_img[2]
#         v_img = v_img / np.linalg.norm(v_img)
#         cos_theta = np.dot(v_img, line_dir)
#         loss += 1 - cos_theta ** 2
#     return loss
#
#
# def loss_planar_alignment(omega, R0, K, planar_lines_img):
#     delta_R = R.from_rotvec(omega).as_matrix()
#     R_corr = delta_R @ R0
#     K_inv = np.linalg.inv(K)
#
#     total_loss = 0.0
#     for line_dir in planar_lines_img:
#         line_dir = line_dir / np.linalg.norm(line_dir)
#         dir_img_h = np.array([line_dir[0], line_dir[1], 1.0])
#         dir_cam = K_inv @ dir_img_h
#         dir_cam = dir_cam / np.linalg.norm(dir_cam)
#         dir_world = R_corr.T @ dir_cam
#         z_component = dir_world[2]
#         total_loss += z_component ** 2
#     return total_loss
#
#
# # === –û–±—â–∏–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª ===
#
# def total_loss(omega, R0, K, verticals=None, planar_lines=None, weights=(1.0, 1.0, 10.0)):
#     lambda_vert, lambda_planar, lambda_reg = weights
#     loss = 0.0
#
#     if verticals:
#         loss += lambda_vert * loss_vertical_alignment(omega, R0, K, verticals)
#     if planar_lines:
#         loss += lambda_planar * loss_planar_alignment(omega, R0, K, planar_lines)
#
#     loss += lambda_reg * np.sum(omega ** 2)
#     return loss
#
#
# # === –î–∞–Ω–Ω—ã–µ ===
# K = camera.intrinsics.get()
# params = camera.get_params()
#
# angles = params[1:4]
# R0 = R.from_euler('zyx', angles, degrees=True).as_matrix()
#
# lines_vertical = extract_direction_vectors_from_lines(load_lines('marked/vertical_lines.json'))
# lines_horison = extract_direction_vectors_from_lines(load_lines('marked/horizontal_lines_all.json'))
#
#
# def scaled_loss(scaled_omega, *args):
#     scale = 0.01
#     omega = scaled_omega * scale
#     return total_loss(omega, *args)
#
#
# res = minimize(
#     scaled_loss,
#     np.zeros(3),
#     args=(R0, K, lines_vertical, lines_horison, (1, 1, 100)),
#     method='BFGS'
# )
#
# omega_opt = res.x * 0.01
#
# R_opt = R.from_rotvec(omega_opt).as_matrix() @ R0
# euler_opt = R.from_matrix(R_opt).as_euler('zyx', degrees=True)
#
# print(omega_opt, euler_opt)
#
# camera.extrinsics.set_rotation(euler_opt)
# from calibration.debug import visualize_grid_debug, visualize_grid_gps_debug
#
# point_start = PointND(camera.intrinsics.get_main_point(), add_weight=True)
# visualize_grid_debug(camera, point_start, grid_range=10)
# from calibration.debug import visualize_vps_debug
# visualize_vps_debug(camera, show=True)
v_scene_all = camera.project_back(PointND([492, 769], add_weight=True)).get()[:2]
print(v_scene_all)
v_scene = v_scene_all / np.linalg.norm(v_scene_all)
from calibration.utils import gps_to_enu, enu_to_gps
lat0, lon0 = 54.725377, 55.941040
lat1, lon1 = 54.725211, 55.940847
v_enu_all = gps_to_enu(lat1, lon1, lat0, lon0)
v_enu = v_enu_all / np.linalg.norm(v_enu_all)
cos_theta = np.dot(v_scene, v_enu)
sin_theta = v_scene[0] * v_enu[1] - v_scene[1] * v_enu[0]
theta = np.arctan2(sin_theta, cos_theta)
R = np.array([
    [np.cos(theta), -np.sin(theta)],
    [np.sin(theta), np.cos(theta)]
])
print(enu_to_gps(*R @ v_scene_all, lat0, lon0))
point_test_gps = annotation_parser.get_points_by_class("gps_test")
point_gps = []
for point in point_test_gps:
    _point_world = camera.project_back(PointND(point, add_weight=True)).get()[:2]
    _point_enu = enu_to_gps(*R @ _point_world, lat0, lon0)
    point_gps.append(_point_enu)
def generate_yandex_maps_url(points):
    base_url = "https://yandex.ru/maps/?pt="
    coords = ["{:.6f},{:.6f}".format(lon, lat) for lat, lon in points]
    return base_url + "~".join(coords)
url = generate_yandex_maps_url(point_gps)
print("–°—Å—ã–ª–∫–∞ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç–∞—Ö:")
print(url)
point_gps_ideal = [(54.725194, 55.940845),
                   (54.725242, 55.940414),
                   (54.725295, 55.940380),
                   (54.725469, 55.940450),
                   (54.725567, 55.940570)
                  ]
error = []
for _point_gps, _point_gps_ideal in zip(point_gps, point_gps_ideal):
    # print(_point_gps, _point_gps_ideal)
    _point_enu = np.array(gps_to_enu(*_point_gps, lat0, lon0))
    _point_enu_ideal = np.array(gps_to_enu(*_point_gps_ideal, lat0, lon0))
    dist = np.linalg.norm(_point_enu_ideal - _point_enu)
    error.append(dist)
print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—à–∏–±–æ–∫ (–≤ –º–µ—Ç—Ä–∞—Ö):")
print(f"  ‚ñ∏ –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞:      {np.mean(error):.2f} –º")
print(f"  ‚ñ∏ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {np.std(error):.2f} –º")
print(f"  ‚ñ∏ –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞:  {np.min(error):.2f} –º")
print(f"  ‚ñ∏ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {np.max(error):.2f} –º")
print(f"  ‚ñ∏ –ú–µ–¥–∏–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞:    {np.median(error):.2f} –º")
# ==== example/karls_marks/example_traking.py ====
from ultralytics import YOLO
model = YOLO("yolov8n.pt")
model.track(source="D:\Final qualifying work\Main\other\load_video_ufanet\output.mp4", show=True, save=True)# ==== example/trassa/example.py ====
from source import CalibrationPipeline, Camera, VanishingPointCalibration, \
    RefineOptimizer
from source.utils import load_lines, load_lines_from_json
from calibration.refine import residual_interline_distance, residual_parallel_group, \
    residual_reprojection_line
from calibration.debug import load_scene_gps, visualize_source
from vp_detection import VanishingPointEstimatorManual
import numpy as np
# from utils.data_markup_tool import LineAnnotationTool
#
# line_tool = LineAnnotationTool("image/pattern_corrected_image.png","marked","dist_ between_line_2.json")
# line_tool.run()
lines_vp1 = load_lines("marked/horizontal_lines.json")
lines_vp3 = load_lines("marked/vertical_lines.json")
#
vp1_manual = VanishingPointEstimatorManual().estimate(lines_vp1)
vp3_manual = VanishingPointEstimatorManual().estimate(lines_vp3)
#
vps_manual = np.array([vp1_manual, vp3_manual])
#
camera = Camera('image/pattern_corrected_image.png')
vp_init = VanishingPointCalibration(camera, debug_save_path='image/vp.png')
#
vp_init.set_vanishing_points(vpX=vps_manual[0], vpZ=vps_manual[1])
data = {
    "dist_between_line_1": load_lines('marked/dist_ between_line_1.json'),
    "dist_between_line_2": load_lines('marked/dist_ between_line_2.json'),
}
resualds_blocks = [
    lambda cam, data: residual_interline_distance(cam, data, group="dist_between_line_1", expected=4),
    lambda cam, data: residual_interline_distance(cam, data, group="dist_between_line_2", expected=4),
]
refiner_first = RefineOptimizer(camera=camera,
                                    residual_blocks=resualds_blocks,
                                    mask=[0, 6],
                                    bounds=([700, 1], [2000, 30]),
                                    debug_save_path='image/',
                                    )
pipeline = CalibrationPipeline([vp_init, refiner_first])
camera = pipeline.run(camera, data)
